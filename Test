#OOO Flag, forces the error emails to go to Lauri and Luke while I am out

def date_function():
    import time
    timestr = time.strftime("%m%d%y")
    return timestr

date_function()

date = str(date_function())
date = date[:2] + '/' + date[2:4] + '/' + date[4:6]

pto_date_list = [
    "12/26/24"
    ,"1/27/25"
    , "1/29/25"
    , "1/31/25"
    , "2/6/25"
    , "2/16/25"
    , "3/14/25"
    , "3/31/25"
    , "4/21/25"
    , "4/22/25"
    , "4/23/25"
    , "4/24/25"
    , "4/25/25"
    , "4/28/25"
    , "4/29/25"
    , "4/30/25"
    , "5/1/25"
    , "5/2/25"
    , "5/9/25"
    , "6/3/25"
    , "7/1/25"
    , "8/1/25"
    , "9/15/25"
    , "9/19/25"
    , "11/28/25"
    , "12/27/25"
    , "12/29/25"
    ]

global OOO

if date in pto_date_list:
    OOO = "Y"
else:
    OOO = "N"
    
print("Out of Office?: " + OOO)


#%%
#import packages

import pyodbc
import pandas as pd

import schedule
import time
import datetime

import warnings
warnings.filterwarnings('ignore')
import sys
import os

import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.message import EmailMessage
from email import encoders
from email.mime.base import MIMEBase

import trino
import io

import openpyxl
from openpyxl import Workbook, load_workbook
from openpyxl.styles import Alignment

import untitled18 as u
import untitled17 as p
import untitled3 as st_u
import untitled2 as st_p

#%% Queries and Email List
#All the queries used in this script

Calls_WeeklyReporting = """
select 
max(cast(event_week_start as date)) as "Max Event Week End"
,dateadd(day, -16, cast(getdate() as date)) as "Current Date"
,case when max(cast(event_week_start as date))  = dateadd(day, -16, cast(getdate() as date)) then 1 else 0 end as "Flag"
from [NFO_Analytics].[Genesis].[Calls_WeeklyReporting]
having case when max(cast(event_week_start as date))  = dateadd(day, -16, cast(getdate() as date)) then 1 else 0 end = 0
"""

TCs_WeeklyReporting = """
select 
max(cast(event_week_start as date)) as "Max Event Week End"
,dateadd(day, -16, cast(getdate() as date)) as "Current Date"
,case when max(cast(event_week_start as date))  = dateadd(day, -16, cast(getdate() as date)) then 1 else 0 end as "Flag"
from  [NFO_Analytics].[Genesis].[TCs_WeeklyReporting]
having case when max(cast(event_week_start as date))  = dateadd(day, -16, cast(getdate() as date)) then 1 else 0 end = 0
"""

PSNB_vs_Spatial_Trending = """
select 
max(loaded_date) as Max_Date
,cast(getdate() as date) as "Todays Date"
,case when max(loaded_date) = cast(getdate() as date) then 1 else 0 end as "TF"
from [node_analytics].[dbo].[PSNB_vs_Spatial_Trending]
having case when max(loaded_date) = cast(getdate() as date) then 1 else 0 end = 0
"""

PS_Missing_EGIS_Daily = """
select cast(getdate() as date) today
,max(loaded_date) loaded_date
from node_analytics.dbo.Power_Supply_MissingEGIS_daily
having cast(getdate() as date) <> max(loaded_date)
"""

ONTRAC_Combined_Orders = """
select CompleteDateDT Date,
   datename(weekday,CompleteDateDT) 'WeekDay',
   sum(case when OrderType='Install' then 1 else 0 end ) Install,
   sum(case when OrderType='TC' then 1 else 0 end ) TC,
   sum(case when OrderType='SRO' then 1 else 0 end ) SRO,
   sum(IsAvoidableFlg) Avoidable,
   sum(TimeInHouseFlg) TimeInHouse,
   coalesce(sum(IsContact48hrFlg),0) Contact48hr,
   sum(IsReworkFlg) ReworkFlg,
   sum(IsFTRContact_DenominatorFlg) FTRContact_Den,
   sum(IsFTRFailFlg) FTRFailFlg,
   sum(IsFTRReworkFlg) FTRReworkFlg,
   coalesce(sum(TUEligible),0) TUEligible,
   sum(case when pht_id is not null then 1 else 0 end) PHT,
   sum(case when Phone_LTR is not null then 1 else 0 end ) tNPS
FROM [comtrac_dw].[Reporting].[vw_ONTRAC_Combined_Orders]
where CompleteDateDT >=GETDATE()-9
and OrderStatus = 'C'
group by CompleteDateDT,datename(weekday,CompleteDateDT)
order by CompleteDateDT desc
"""

ONTRAC_Linda_PHT = """
select CompleteDateDT,
   datename(weekday,CompleteDateDT) 'WeekDay',
   sum(case when OrderType='Install' then 1 else 0 end ) Install,
   sum(case when OrderType='TC' then 1 else 0 end ) TC,
   sum(case when OrderType='SRO' then 1 else 0 end ) SRO,
   sum(IsAvoidableFlg) Avoidable,
   sum(TimeInHouseFlg) TimeInHouse,
   coalesce(sum(IsContact48hrFlg),0) Contact48hr,
   sum(IsReworkFlg) ReworkFlg,
   sum(IsFTRContact_DenominatorFlg) FTRContact_Denominator,
   sum(IsFTRFailFlg) FTRFailFlg,
   sum(IsFTRReworkFlg) FTRReworkFlg,
   coalesce(sum(TUEligible),0) TUEligible,
   sum(case when pht_id is not null then 1 else 0 end) PHT,
   sum(case when Phone_LTR is not null then 1 else 0 end ) tNPS
FROM [comtrac_dw].[Reporting].[vw_ONTRAC_Combined_Orders]
where CompleteDateDT >= '2023-03-25'
group by CompleteDateDT,datename(weekday,CompleteDateDT)
order by CompleteDateDT desc
"""

Node_Analytics_Outage_Detection = """
SELECT top 10 N2PSA.[fiscal_month_end]
,coalesce(sum(N2PSA.[not_in_continuity]),0) "N2PSA Num Not in Continuity"
,coalesce(sum(N2PSA.[node_count]),0) "N2PSA Den - Node Count"
,sum(OUTAGE_N2PSA.not_in_continuity_node_outages) "Outage N2PSA - Not in Continuity Node Outages"
,sum(OUTAGE_N2PSA.node_outage_count) "Outage N2PSA Den - Node Outage Count"
,coalesce(sum(totalaffected),0) "Plant Stability  Num - Total Affected"
,cast(coalesce(sum(totalaccounts_daylevel),0) as float) "Plant Stability Den - Total Accounts Day Level" 
FROM [node_analytics].[dbo].[N2PSA_final] N2PSA

--ACP
LEFT JOIN (
	select top 10 
	datefromparts(fiscal_year_id,fiscal_month_number,21)[fiscal_month_end]
	,sum(totaldevicecount) ACP_totaldevicecount
	,sum(acpcount) acp_count
	from node_analytics.dbo.acp_device
	group by datefromparts(fiscal_year_id,fiscal_month_number,21)
	order by datefromparts(fiscal_year_id,fiscal_month_number,21) desc
) ACP ON ACP.fiscal_month_end = N2PSA.fiscal_month_end

--PLANT STABILITY
LEFT JOIN (
select top 10 
datefromparts(fiscal_year_id,fiscal_month_number,21)[fiscal_month_end]
,sum(totalaffected) totalaffected
,sum(totalaccounts_daylevel) totalaccounts_daylevel
from node_analytics.dbo.plant_stability
group by datefromparts(fiscal_year_id,fiscal_month_number,21)
order by datefromparts(fiscal_year_id,fiscal_month_number,21) desc
) PS ON PS.fiscal_month_end = N2PSA.[fiscal_month_end]

--OUTAGE N2PSA
LEFT JOIN (
	select a.fiscalmonth
	,coalesce(sum(b.not_in_continuity_node_outages),0)not_in_continuity_node_outages
	,coalesce(sum(a.node_outage_count),0) node_outage_count
	from (
	select fiscalmonth,divisionname,regionname,headend
	,sum(Total_Outages) node_outage_count
	from [node_analytics].[dbo].[Outage_N2PSA]
	--where headend = 'lyndon.mi' and fiscalmonth = '2021-08-21'
	group by fiscalmonth,divisionname,regionname,headend
	) a
	left join (
	select a.fiscalmonth,a.divisionname,a.region,b.headend
	,sum(not_in_continuity)not_in_continuity_node_outages,sum(CommercialPower_Outage)CommercialPower_Outage
	,sum(other_outage)other_outage,sum(total_outages)total_outages
	from [node_analytics].[dbo].[N2PSA] a
	join [node_analytics].[dbo].[Outage_N2PSA] b on a.fiscalmonth = b.fiscalmonth and a.region = b.regionname and a.ncpcmts = b.cmts and a.ncpnode = b.node and b.total_outages = 1
	--where headend = 'lyndon.mi'
	group by a.fiscalmonth,a.divisionname,a.region,b.headend
	) b on a.fiscalmonth = b.fiscalmonth and a.regionname = b.region and a.headend = b.headend
	group by a.fiscalmonth
) OUTAGE_N2PSA
on OUTAGE_N2PSA.fiscalmonth = N2PSA.[fiscal_month_end]
group by N2PSA.[fiscal_month_end]
order by 1 desc
"""

Power_Supply_Outage_Detection = """
select 
Power_Supply_MissingEGIS_CreatedDate.Date
, Power_Supply_MissingEGIS_CreatedDate PS_MissingEGIS_CreatedDate
, Power_Supply_MissingEGIS_daily PS_MissingEGIS_daily
, Power_Supply_NodeCount_daily PS_NodeCount_daily
, Power_Supply_NodeidMismatch_daily PS_NodeidMismatch_daily
, Power_Supply_WT_RO PS_WT_RO
, "Power_Supply_WT_RO_90_vac" "PS_WT_RO_90_vac"
, "Power_Supply_WT_RO_includes_unmonitored" "PS_WT_RO_includes_unmonitored"
,"Power_Supply_MissingEGIS_daily_headend" "PS_Missing_EGIS_Daily_Headend"
from
--10/2
(
select cast(Loaded_Date as date) Date, count(*) as "Power_Supply_MissingEGIS_daily" 
from [node_analytics].[dbo].Power_Supply_MissingEGIS_daily
where cast(Loaded_Date as date) >= cast(getdate() - 7 as date)
group by cast(Loaded_Date as date)
) Power_Supply_MissingEGIS_CreatedDate
--10/3
left join 
(
select createddate Date, count(*) as "Power_Supply_MissingEGIS_CreatedDate" 
from [node_analytics].[dbo].Power_Supply_MissingEGIS_CreatedDate cd
where CREATEDDATE >= cast(getdate() - 7 as date)
group by createddate
) Power_Supply_MissingEGIS_daily
on Power_Supply_MissingEGIS_daily.Date = Power_Supply_MissingEGIS_CreatedDate.Date
--10/3
left join 
(
select cast(Loaded_Date as date) Date, count(*) as "Power_Supply_NodeCount_daily" 
from [node_analytics].[dbo].Power_Supply_NodeCount_daily
where cast(Loaded_Date as date) >= cast(getdate() - 7 as date)
group by cast(Loaded_Date as date)
) Power_Supply_NodeCount_daily
on Power_Supply_NodeCount_daily.Date = Power_Supply_MissingEGIS_CreatedDate.Date

left join 
(
select cast(Loaded_Date as date) Date, count(*) as "Power_Supply_NodeidMismatch_daily" 
from [node_analytics].[dbo].Power_Supply_NodeidMismatch_daily
where cast(Loaded_Date as date) >= cast(getdate() - 7 as date)
group by cast(Loaded_Date as date)
) Power_Supply_NodeidMismatch_daily
on Power_Supply_NodeidMismatch_daily.Date = Power_Supply_MissingEGIS_CreatedDate.Date

left join 
(
select cast(Loaded_Date as date) Date, count(*) as "Power_Supply_WT_RO" 
from [node_analytics].[dbo].Power_Supply_WT_RO
where cast(Loaded_Date as date) >= cast(getdate() - 7 as date)
group by cast(Loaded_Date as date)
) Power_Supply_WT_RO
on Power_Supply_WT_RO.Date = Power_Supply_MissingEGIS_CreatedDate.Date
--10/3
left join 
(
select cast(Loaded_Date as date) Date, count(*) as "Power_Supply_WT_RO_90_vac" 
from [node_analytics].[dbo].Power_Supply_WT_RO_90_vac
where cast(Loaded_Date as date) >= cast(getdate() - 7 as date)
group by cast(Loaded_Date as date)
) Power_Supply_WT_RO_90_vac
on Power_Supply_WT_RO_90_vac.Date = Power_Supply_MissingEGIS_CreatedDate.Date

left join 
(
select cast(Loaded_Date as date) Date, count(*) as "Power_Supply_WT_RO_includes_unmonitored" 
from [node_analytics].[dbo].Power_Supply_WT_RO_includes_unmonitored
where cast(Loaded_Date as date) >= cast(getdate() - 7 as date)
group by cast(Loaded_Date as date)
) Power_Supply_WT_RO_includes_unmonitored
on Power_Supply_WT_RO_includes_unmonitored.Date = Power_Supply_MissingEGIS_CreatedDate.Date

left join 
(
select cast(loaded_date as date) Date, count(*) as "Power_Supply_MissingEGIS_daily_headend"
from node_analytics.[dbo].[Power_Supply_MissingEGIS_daily_headend]
where cast(Loaded_Date as date) >= cast(getdate() - 7 as date)
group by cast(loaded_date as date)
) Power_Supply_MissingEGIS_daily_headend 
on Power_Supply_MissingEGIS_daily_headend.Date = Power_Supply_MissingEGIS_CreatedDate.Date

order by Power_Supply_MissingEGIS_CreatedDate.Date asc
"""

TechMPJProductivity = """
select
case when "Tech Productivity" > 1 then 1
when "Tech Productivity" < .1 then 1
else 0
end as "Flag"
from
(
select
CompleteDate
,cast(sum(TotalHours) as float)/cast(sum(AvailableHours) as float) as "Tech Productivity"
from comtrac_dw.reporting.TechMPJProductivity
where CompleteDate >= getdate()-9 and completedate <getdate()-4
group by CompleteDate
) a
group by case when "Tech Productivity" >1 then 1 when "Tech Productivity" < .1 then 1 else 0 end
having case when "Tech Productivity" >1 then 1 when "Tech Productivity" < .1 then 1 else 0 end = 1
""" 

SQL_Server_Jobs = """
select b.*, 
	case when Last_Successful_Run IS NULL then '9999-12-31' 
	else Last_Successful_Run
	end as Last_Successful_Run
	from 
	(
select 
a.step_name as "Package"
, a.message as "Message"
, a."Run Date"
,a.run_duration as "Run Duration"
	--,l.Max_Run_Date
,avg(b.run_duration) as "Avg. Run Duration (prev 10 runs)"
,a.run_status
,case when avg(b.run_duration) = 0 then 1
when cast(a.run_duration as float) / cast(avg(b.run_duration) as float) <= .1 then 1 
else 0 end as "Flag"
from 
(
SELECT step_name
,run_status
,run_duration
,message
,cast(cast(run_date as varchar(10)) as date) as "Run Date" 
,rank() over (partition by step_name order by instance_id desc) as "Rank"
FROM msdb.dbo.sysjobhistory
where run_duration > 0
and step_name <> '(Job outcome)'
) a
inner join
(
SELECT step_name
,run_status
,run_duration
,message
,cast(cast(run_date as varchar(10)) as date) as "Run Date" 
,rank() over (partition by step_name order by instance_id desc) as "Rank"
FROM msdb.dbo.sysjobhistory
where run_duration > 0
and step_name <> '(Job outcome)'
) b
on a.step_name = b.step_name
where a."Rank" = 1
and b."Rank" > 1
group by 
a.step_name
, a.message
, a."Run Date"
,a.run_duration
,a.run_status
having case when avg(b.run_duration) = 0 then 1
when cast(a.run_duration as float) / cast(avg(b.run_duration) as float) <= .1 then 1 
else 0 end = 1

UNION

select * from
(
select 
a.step_name as "Package"
, a.message as "Message"
, CONVERT(date, CONVERT(varchar(8), run_date), 112) as "Run Date"
,a.run_duration as "Run Duration"
,'0' as "Avg. Run Duration (prev 10 runs)"
,run_status
,rank() over (partition by a.step_name, run_date order by instance_id desc) as "Rank"
from msdb.dbo.sysjobhistory a
where run_status = 0
and step_name <> '(Job outcome)'
and CONVERT(date, CONVERT(varchar(8), run_date), 112) = cast(getdate() as date)
) a
	Where "Rank" = 1
	) b
	left join 
		(
			select 
			step_name
			,max("Run Date") as Last_Successful_Run
			from
			(
			select 
			distinct
			step_name
			,CONVERT(date, CONVERT(varchar(8), run_date), 112) as "Run Date"
			,run_status FROM msdb.dbo.sysjobhistory
			) a
			where run_status = 1
			group by step_name
		) l on l.step_name = b."Package"
where b.[Run Date] >= CONVERT(DATE, DATEADD(DAY, -8, GETDATE()))
and package <> 'Back up databases to Azure Blob Container'
"""

SQL_Server_Jobs_24_Hours = """
SELECT 
    j.name AS Package
    ,ja.start_execution_date
    ,CASE 
        WHEN ja.stop_execution_date IS NULL THEN 'Running'
        ELSE 'Not Running'
    END AS job_status
	,DATEDIFF(SECOND, ja.start_execution_date, GETDATE()) AS active_duration_seconds
	,case when DATEDIFF(SECOND, ja.start_execution_date, GETDATE()) > 86400 then 1 else 0 end as "24_Hour_Flag"
FROM msdb.dbo.sysjobs j
INNER JOIN msdb.dbo.sysjobactivity ja
    ON j.job_id = ja.job_id
WHERE ja.start_execution_date IS NOT NULL
    AND ja.stop_execution_date IS NULL
	AND start_execution_date >= DATEADD(DAY, -7, GETDATE())
	AND case when DATEDIFF(SECOND, ja.start_execution_date, GETDATE()) > 86400 then 1 else 0 end = 1
	AND j.name not in (
	'collection_set_2_collection'
	,'collection_set_1_noncached_collect_and_upload'
	,'collection_set_2_collection'
	,'collection_set_2_upload'
	,'collection_set_3_collection'
	,'collection_set_3_upload'
	)
order by 2 desc
"""

Spectra_Query = """
SELECT 
date(max(day_id))
,CASE WHEN date(max(day_id)) >= date_trunc('day', current_date - interval '2' day) THEN 1 ELSE 0 END AS flag
FROM minio.dx_dl_comcast_source.comet_sik_spectra
having CASE WHEN date(max(day_id)) >= date_trunc('day', current_date - interval '2' day) THEN 1 ELSE 0 END = 0
"""

Spectra_Query_Last_7_Days = """
SELECT 
day_id as "Date"
,count(*) as "Count"
,'minio.dx_dl_comcast_source.comet_sik_spectra' as "Table_Name"
FROM minio.dx_dl_comcast_source.comet_sik_spectra
where date(day_id) >= date_trunc('day', current_date - interval '7' day)
group by day_id
order by day_id desc
"""

Turners_Poll_Query = """
select max(day_id ) as Max_Date
,CASE WHEN date(max(day_id)) >= date_trunc('day', current_date - interval '6' day) THEN 1 ELSE 0 END AS flag 
from minio.dx_dl_comcast_network.device_stb_tuners_poll
having CASE WHEN date(max(day_id)) >= date_trunc('day', current_date - interval '6' day) THEN 1 ELSE 0 END = 0
"""

Turners_Poll_Last_7_Days = """
select day_id, count(*) as "Count"
,'minio.dx_dl_comcast_network.device_stb_tuners_poll' as "Table_Name"
from minio.dx_dl_comcast_network.device_stb_tuners_poll
group by day_id
order by day_id desc
limit 7
"""

california_query = """
with acc as(
select distinct csg_account_number as account_number
from datalake.dx_dl_rd_comcast_enhanced.equipment_device_account a
inner join datalake.dx_dl_rd_comcast_enhanced.equipment_device_component c on a.device_uuid = c.device_uuid
and a.exp_dt = '9999-12-31'  and a.audit_information_source_code like '%CSG%'
and c.exp_dt = '9999-12-31' and c.audit_information_source_code like '%CSG%'
and c.component_status_code = 'Active'
)

,node_inv as (
select max(lastpoll)lastpoll,lower(headend)headend,cmts,node
from minio.dx_dl_comcast_source.watchtower_defined_nwt_network_inv_node_hist
--meld.jrnl.defined_nwt_network_inv_node_hist
where current_record_ind = 'Y'
group by 2,3,4
)

,TotalAccounts as (
select
cast(da.calendar_date as varchar) snapshot_date
,o.division_name
,case when o.region_name = 'CHICAGO REGION' then 'GREATER CHICAGO' ELSE replace(o.region_name,' REGION','') end region_name
,lower(l.headend_name) headend,lower(l.cmts_name) cmts,l.fiber_node_name node_name
--,concat(cast(case when month(current_date) = 12 and day(current_date) between 22 and 31 then year(current_date + interval  '1' year)  else year(current_date)  end as varchar),'-',lpad(cast(case when day(current_date) between 1 and 21 then month(current_date) else month(current_date + interval '1' month)  end as varchar),2,'0'),'-','21') as fiscal_month_end
,approx_distinct(customer_account_id ,0.0040625) Total_Accounts
from deltalake.dx_dl_rd_comcast_source.ndw_customer_account_history ca
join deltalake.dx_dl_rd_comcast_enhanced.location_location l on ca.location_id = l.ndw_location_id
join deltalake.dx_dl_rd_comcast_source.ndw_organization_hierarchy_hist o on ca.organization_id = o.organization_id
join acc on acc.account_number = ca.account_number
join minio.dx_dl_comcast_source.static_date_dim da
on da.calendar_date between ca.ndw_record_start_ts and ndw_record_end_ts
and da.calendar_date between current_date - interval '30' day and current_date
where ca.record_end_dt = '9999-12-31' 
and l.record_end_date = date('9999-12-31') 
and o.record_end_dt = date('9999-12-31')
and case when o.region_name = 'CHICAGO REGION' then 'GREATER CHICAGO' ELSE replace(o.region_name,' REGION','') end = 'CALIFORNIA'
group by 1,2,3,4,5,6
)

,min_wt as (
select day_id,id,min(lastrescandatetime)min_lastrescandatetime
from minio.dx_dl_comcast_source.watchtower_events
where TYPE IN (22,23,24,30,31)
and day_id <> '2022-07-23'
and date(day_id) between current_date - interval '30' day and current_date
group by day_id,id
)

,inventoryid_t as (
select inventoryid,max(cast(date(lastpoll) as varchar)) max_lastpoll 
from minio.dx_dl_comcast_source.watchtower_defined_nwt_network_inv_node_hist
group by inventoryid
)

,inv as (
select distinct h.inventoryid
,n.division_name divisionname
,n.region_name regionname
,headend
,node
,try(cast(date(lastpoll) as varchar)) lastpoll
from minio.dx_dl_comcast_source.watchtower_defined_nwt_network_inv_node_hist h
join inventoryid_t t on h.inventoryid = t.inventoryid and t.max_lastpoll = cast(date(h.lastpoll) as varchar)
join 
(
	select distinct division_name
	,case when region_name in ('BELTWAY MARKET', 'BELTWAY REGION') then 'BELTWAY'
	when region_name in ('BIG SOUTH REGION') then 'BIG SOUTH'
	when region_name in ('CALIFORNIA MARKET', 'CALIFORNIA REGION') then 'CALIFORNIA'
	when region_name in ('CHICAGO REGION', 'GREATER CHICAGO MARKET') then 'CHICAGO'
	when region_name in ('FLORIDA REGION') then 'FLORIDA'
	when region_name in ('FREEDOM MARKET', 'FREEDOM REGION') then 'FREEDOM'
	when region_name in ('GREATER BOSTON MARKET', 'NEW ENGLAND REGION', 'WESTERN NEW ENGLAND MARKET') then 'NEW ENGLAND'
	when region_name in ('HEARTLAND REGION') then 'HEARTLAND'
	when region_name in ('HOUSTON MARKET', 'TEXAS REGION') then 'TEXAS'
	when region_name in ('KEYSTONE MARKET', 'KEYSTONE REGION') then 'KEYSTONE'
	when region_name in ('MANAGED ENTITIES') then 'MANAGED ENTITIES'
	when region_name in ('MIDWEST REGION', 'TWIN CITIES MARKET') then 'MIDWEST'
	when region_name in ('MOUNTAIN WEST REGION') then 'MOUNTAIN WEST'
	when region_name in ('PACIFIC NORTHWEST REGION', 'PORTLAND/SALEM MARKET', 'SEATTLE MARKET') then 'PACIFIC NORTHWEST'
	else region_name
	end as region_name
	,entity_id
	from datalake.dx_dl_comcast_enhanced.businesshierarchy_business_hierarchy
	where exp_dt = '9999-12-31'
	and region_name not in ('MANAGED ENTITIES', 'HEADQUARTERS')
) n on n.entity_id = try(cast(h.systemid as varchar))
)


,wt as (
select wt.day_id,wt.id as "event_id",divisionname,regionname,headend,node,nodeid
,case when type = 30 then num_res_affected+num_comm_affected else 0 end as "UpstreamTiltAffected"
,case when type = 31 then num_res_affected+num_comm_affected else 0 end as "DownstreamWobble"
,case when type = 24 then (num_res_affected+num_comm_affected)*2 else 0 end as "Suckout_Severe_x2"
,case when type = 23 then num_res_affected+num_comm_affected else 0 end as "Suckout_Moderate"
,case when type = 22 then num_res_affected+num_comm_affected else 0 end as "Wave"
,case when type = 24 then (num_res_affected+num_comm_affected)*2 else num_res_affected+num_comm_affected end as "TotalAffected"
from /*meld.base.wt_events*/ minio.dx_dl_comcast_source.watchtower_events wt
join min_wt on wt.id = min_wt.id and wt.lastrescandatetime = min_wt.min_lastrescandatetime
join inv on inv.inventoryid = wt.nodeid
--join date_join dj on dj.date_id = wt.day_id
where TYPE IN (22,23,24,30,31) --and wt.day_id between '2021-04-22' and '2021-05-21'  /*and active = '1'*/ --and wt.id in (2557553427,2557553424)
and wt.day_id <> '2022-07-23'
and date(wt.day_id) between current_date - interval '30' day and current_date
)


,final_maybe as (
select ta.snapshot_date,da.fiscal_month_num  fiscal_month_number, da.fiscal_year_num  fiscal_year_id,ta.division_name,ta.region_name,ta.headend,ta.cmts,ta.node_name,wt.nodeid
--,UPstreamTiltAffected,Suckout_Severe_x2,Suckout_Moderate,Wave,wt.id,totalaffected,totalaccounts
,sum(DownstreamWobble)DownstreamWobble
,sum(UPstreamTiltAffected)UPstreamTiltAffected
,sum(Suckout_Severe_x2)Suckout_Severe_x2
,sum(Suckout_Moderate)Suckout_Moderate
,sum(Wave)Wave
,approx_distinct (wt.event_id,0.0040625) as "#ofEvents"
,sum(TotalAffected)TotalAffected
,avg(Total_Accounts)TotalAccounts
from TotalAccounts ta
left join wt on wt.node = ta.node_name and wt.headend = ta.headend and ta.snapshot_date = wt.day_id
join minio.dx_dl_comcast_source.static_date_dim da on cast(da.calendar_date as varchar)  = ta.snapshot_date
group by 1,2,3,4,5,6,7,8,9
)

select /*fiscal_month_number,fiscal_year_id,*/division_name,region_name,headend, node_name
,cast(sum(coalesce(TotalAffected,0)) as decimal(10,2)) / cast(sum(TotalAccounts) as decimal(10,2)) "Plant Stability"
,sum(coalesce(UPstreamTiltAffected,0))UpStreamTiltAffected
,sum(coalesce(Suckout_Severe_x2,0))Suckout_Severe_x2
,sum(coalesce(Suckout_Moderate,0))Suckout_Moderate
,sum(coalesce(Wave,0))Wave
,sum("#ofEvents") as "#ofEvents"
,approx_distinct (node_name,0.0040625)NodeCount_monthlevel
,sum(coalesce(TotalAffected,0))TotalAffected
,sum(TotalAccounts)TotalAccounts_DAYlevel
,round(sum(TotalAccounts)/count(distinct snapshot_date),0)TotalAccounts_MONTHlevel
,sum(coalesce(DownstreamWobble,0)) as DownstreamWobble
from final_maybe
where headend is not null
group by 1,2,3,4
order by 5 desc
limit 300
"""

pnw_query = """
with acc as(
select distinct csg_account_number as account_number
from datalake.dx_dl_rd_comcast_enhanced.equipment_device_account a
inner join datalake.dx_dl_rd_comcast_enhanced.equipment_device_component c on a.device_uuid = c.device_uuid
and a.exp_dt = '9999-12-31'  and a.audit_information_source_code like '%CSG%'
and c.exp_dt = '9999-12-31' and c.audit_information_source_code like '%CSG%'
and c.component_status_code = 'Active'
)

,node_inv as (
select max(lastpoll)lastpoll,lower(headend)headend,cmts,node
from minio.dx_dl_comcast_source.watchtower_defined_nwt_network_inv_node_hist
--meld.jrnl.defined_nwt_network_inv_node_hist
where current_record_ind = 'Y'
group by 2,3,4
)

,TotalAccounts as (
select
cast(da.calendar_date as varchar) snapshot_date
,o.division_name
,case when o.region_name = 'CHICAGO REGION' then 'GREATER CHICAGO' ELSE replace(o.region_name,' REGION','') end region_name
,lower(l.headend_name) headend,lower(l.cmts_name) cmts,l.fiber_node_name node_name
--,concat(cast(case when month(current_date) = 12 and day(current_date) between 22 and 31 then year(current_date + interval  '1' year)  else year(current_date)  end as varchar),'-',lpad(cast(case when day(current_date) between 1 and 21 then month(current_date) else month(current_date + interval '1' month)  end as varchar),2,'0'),'-','21') as fiscal_month_end
,approx_distinct(customer_account_id ,0.0040625) Total_Accounts
from deltalake.dx_dl_rd_comcast_source.ndw_customer_account_history ca
join deltalake.dx_dl_rd_comcast_enhanced.location_location l on ca.location_id = l.ndw_location_id
join deltalake.dx_dl_rd_comcast_source.ndw_organization_hierarchy_hist o on ca.organization_id = o.organization_id
join acc on acc.account_number = ca.account_number
join minio.dx_dl_comcast_source.static_date_dim da
on da.calendar_date between ca.ndw_record_start_ts and ndw_record_end_ts
and da.calendar_date between current_date - interval '30' day and current_date
where ca.record_end_dt = '9999-12-31' 
and l.record_end_date = date('9999-12-31') 
and o.record_end_dt = date('9999-12-31')
and case when o.region_name = 'CHICAGO REGION' then 'GREATER CHICAGO' ELSE replace(o.region_name,' REGION','') end = 'PACIFIC NORTHWEST'
group by 1,2,3,4,5,6
)

,min_wt as (
select day_id,id,min(lastrescandatetime)min_lastrescandatetime
from minio.dx_dl_comcast_source.watchtower_events
where TYPE IN (22,23,24,30,31)
and day_id <> '2022-07-23'
and date(day_id) between current_date - interval '30' day and current_date
group by day_id,id
)

,inventoryid_t as (
select inventoryid,max(cast(date(lastpoll) as varchar)) max_lastpoll 
from minio.dx_dl_comcast_source.watchtower_defined_nwt_network_inv_node_hist
group by inventoryid
)

,inv as (
select distinct h.inventoryid
,n.division_name divisionname
,n.region_name regionname
,headend
,node
,try(cast(date(lastpoll) as varchar)) lastpoll
from minio.dx_dl_comcast_source.watchtower_defined_nwt_network_inv_node_hist h
join inventoryid_t t on h.inventoryid = t.inventoryid and t.max_lastpoll = cast(date(h.lastpoll) as varchar)
join 
(
	select distinct division_name
	,case when region_name in ('BELTWAY MARKET', 'BELTWAY REGION') then 'BELTWAY'
	when region_name in ('BIG SOUTH REGION') then 'BIG SOUTH'
	when region_name in ('CALIFORNIA MARKET', 'CALIFORNIA REGION') then 'CALIFORNIA'
	when region_name in ('CHICAGO REGION', 'GREATER CHICAGO MARKET') then 'CHICAGO'
	when region_name in ('FLORIDA REGION') then 'FLORIDA'
	when region_name in ('FREEDOM MARKET', 'FREEDOM REGION') then 'FREEDOM'
	when region_name in ('GREATER BOSTON MARKET', 'NEW ENGLAND REGION', 'WESTERN NEW ENGLAND MARKET') then 'NEW ENGLAND'
	when region_name in ('HEARTLAND REGION') then 'HEARTLAND'
	when region_name in ('HOUSTON MARKET', 'TEXAS REGION') then 'TEXAS'
	when region_name in ('KEYSTONE MARKET', 'KEYSTONE REGION') then 'KEYSTONE'
	when region_name in ('MANAGED ENTITIES') then 'MANAGED ENTITIES'
	when region_name in ('MIDWEST REGION', 'TWIN CITIES MARKET') then 'MIDWEST'
	when region_name in ('MOUNTAIN WEST REGION') then 'MOUNTAIN WEST'
	when region_name in ('PACIFIC NORTHWEST REGION', 'PORTLAND/SALEM MARKET', 'SEATTLE MARKET') then 'PACIFIC NORTHWEST'
	else region_name
	end as region_name
	,entity_id
	from datalake.dx_dl_comcast_enhanced.businesshierarchy_business_hierarchy
	where exp_dt = '9999-12-31'
	and region_name not in ('MANAGED ENTITIES', 'HEADQUARTERS')
) n on n.entity_id = try(cast(h.systemid as varchar))
)


,wt as (
select wt.day_id,wt.id as "event_id",divisionname,regionname,headend,node,nodeid
,case when type = 30 then num_res_affected+num_comm_affected else 0 end as "UpstreamTiltAffected"
,case when type = 31 then num_res_affected+num_comm_affected else 0 end as "DownstreamWobble"
,case when type = 24 then (num_res_affected+num_comm_affected)*2 else 0 end as "Suckout_Severe_x2"
,case when type = 23 then num_res_affected+num_comm_affected else 0 end as "Suckout_Moderate"
,case when type = 22 then num_res_affected+num_comm_affected else 0 end as "Wave"
,case when type = 24 then (num_res_affected+num_comm_affected)*2 else num_res_affected+num_comm_affected end as "TotalAffected"
from /*meld.base.wt_events*/ minio.dx_dl_comcast_source.watchtower_events wt
join min_wt on wt.id = min_wt.id and wt.lastrescandatetime = min_wt.min_lastrescandatetime
join inv on inv.inventoryid = wt.nodeid
--join date_join dj on dj.date_id = wt.day_id
where TYPE IN (22,23,24,30,31) --and wt.day_id between '2021-04-22' and '2021-05-21'  /*and active = '1'*/ --and wt.id in (2557553427,2557553424)
and wt.day_id <> '2022-07-23'
and date(wt.day_id) between current_date - interval '30' day and current_date
)


,final_maybe as (
select ta.snapshot_date,da.fiscal_month_num  fiscal_month_number, da.fiscal_year_num  fiscal_year_id,ta.division_name,ta.region_name,ta.headend,ta.cmts,ta.node_name,wt.nodeid
--,UPstreamTiltAffected,Suckout_Severe_x2,Suckout_Moderate,Wave,wt.id,totalaffected,totalaccounts
,sum(DownstreamWobble)DownstreamWobble
,sum(UPstreamTiltAffected)UPstreamTiltAffected
,sum(Suckout_Severe_x2)Suckout_Severe_x2
,sum(Suckout_Moderate)Suckout_Moderate
,sum(Wave)Wave
,approx_distinct (wt.event_id,0.0040625) as "#ofEvents"
,sum(TotalAffected)TotalAffected
,avg(Total_Accounts)TotalAccounts
from TotalAccounts ta
left join wt on wt.node = ta.node_name and wt.headend = ta.headend and ta.snapshot_date = wt.day_id
join minio.dx_dl_comcast_source.static_date_dim da on cast(da.calendar_date as varchar)  = ta.snapshot_date
group by 1,2,3,4,5,6,7,8,9
)

select /*fiscal_month_number,fiscal_year_id,*/division_name,region_name,headend, node_name
,cast(sum(coalesce(TotalAffected,0)) as decimal(10,2)) / cast(sum(TotalAccounts) as decimal(10,2)) "Plant Stability"
,sum(coalesce(UPstreamTiltAffected,0))UpStreamTiltAffected
,sum(coalesce(Suckout_Severe_x2,0))Suckout_Severe_x2
,sum(coalesce(Suckout_Moderate,0))Suckout_Moderate
,sum(coalesce(Wave,0))Wave
,sum("#ofEvents") as "#ofEvents"
,approx_distinct (node_name,0.0040625)NodeCount_monthlevel
,sum(coalesce(TotalAffected,0))TotalAffected
,sum(TotalAccounts)TotalAccounts_DAYlevel
,round(sum(TotalAccounts)/count(distinct snapshot_date),0)TotalAccounts_MONTHlevel
,sum(coalesce(DownstreamWobble,0)) as DownstreamWobble
from final_maybe
where headend is not null
group by 1,2,3,4
order by 5 desc
limit 300
"""

#Used in the emails 
Table_Name = ["[NFO_Analytics].[Genesis].[Calls_WeeklyReporting]"
              , "[NFO_Analytics].[Genesis].[TCs_WeeklyReporting]"
              ,"comtrac_dw.reporting.TechMPJProductivity" + "\n\nURL: https://ontrac.cable.comcast.com/Reports/Index?parent=124&menuId=113"
              ,"[node_analytics].[dbo].[PSNB_vs_Spatial_Trending]" + "\n\nURL: https://ts3.comcast.com/#/site/XPM/views/PowerSupplyCleanup/PowerSupplyCleanup?:iid=1"
              ,"node_analytics.dbo.Power_Supply_MissingEGIS_daily"
              ]   

Table_Name_2 = ["[NFO_Analytics].[Genesis].[Calls_WeeklyReporting]"
              , "[NFO_Analytics].[Genesis].[TCs_WeeklyReporting]"
              ,"comtrac_dw.reporting.TechMPJProductivity"
              ,"[node_analytics].[dbo].[PSNB_vs_Spatial_Trending]"
              ,"node_analytics.dbo.Power_Supply_MissingEGIS_daily"
              ]   
 
Table_Name_3 = ["[node_analytics].[dbo].[PSNB_vs_Spatial_Trending]" 
                + "\n\nURL:https://ts3.comcast.com/#/site/XPM/views/PowerSupplyCleanup/PowerSupplyCleanup?:iid=1"]

#Different email lists

email_list_1 = ["tommy_wadelton@comcast.com"
              , "pam_althoff@cable.comcast.com"
              , "lei_zhou@comcast.com"
              , "lauri_bednar@cable.comcast.com"
              , "eleanor_richfield@cable.comcast.com"]

email_list_2 = ["tommy_wadelton@comcast.com"
              , "pam_althoff@cable.comcast.com"
              , "lei_zhou@comcast.com"
              , "lauri_bednar@cable.comcast.com"
              , "luke_briggs@comcast.com"
              , "omar_calderon@cable.comcast.com"
              , "joseph_laryea2@comcast.com"
              , "abraham_stalker@cable.comcast.com"
              , "sobby_mathew@cable.comcast.com"
              , "rick_khounlavouth@cable.comcast.com"
              , "sarvani_rai@comcast.com"
              , "brandon_upah@cable.comcast.com"
              , "david_krauza@cable.comcast.com"
              , "jenny_bulgakova@comcast.com"
              , "kylil_kee-redmond@comcast.com"
              , "himangi_singh@comcast.com"
              ] 

email_list_3 = ["tommy_wadelton@comcast.com"
                ,"lauri_bednar@cable.comcast.com"
                ,"lukas_briggs@comcast.com"
                ]


email_list_4 = ["tommy_wadelton@comcast.com"
                ,"omar_calderon@cable.comcast.com"
                ,"pam_althoff@cable.comcast.com"
                ,"lauri_bednar@cable.comcast.com"
                ,"lei_zhou@comcast.com"
                ]

email_list_6 = ["tommy_wadelton@comcast.com"
                ,"omar_calderon@cable.comcast.com"
                ,"pam_althoff@cable.comcast.com"]

email_list_7 = ["tommy_wadelton@comcast.com"
                ,"omar_calderon@cable.comcast.com"
                ,"pam_althoff@cable.comcast.com"
                ,"lauri_bednar@cable.comcast.com"
                ,"lei_zhou@comcast.com"
                ,"lukas_briggs@comcast.com"
                ]

email_list_psnb_v_spatial = ["tommy_wadelton@comcast.com"
                ,"omar_calderon@cable.comcast.com"
                ,"pam_althoff@cable.comcast.com"
                ,"lauri_bednar@cable.comcast.com"
                ,"lei_zhou@comcast.com"
                ,"jaswanth_moolam@comcast.com"
                ]

email_list_sql_server_24hours = ["tommy_wadelton@comcast.com"
                ,"pam_althoff@cable.comcast.com"
                ,"lauri_bednar@cable.comcast.com"
                ,"lei_zhou@comcast.com"
                ]

email_list_spectra_bois = ["lukas_briggs@comcast.com"
                           ,"tommy_wadelton@comcast.com"]

email_list_team_lauri = ["lukas_briggs@comcast.com"
                           ,"tommy_wadelton@comcast.com"
                           ,"lauri_bednar@cable.comcast.com"]

email_list_IDLE = ['tommy_wadelton@comcast.com'
              , 'lauri_bednar@cable.comcast.com'
              , 'omar_calderon@cable.comcast.com'
              , 'joseph_laryea2@comcast.com'
              , 'lei_zhou@comcast.com'
              #, 'ilka_martin@comcast.com'
              #, 'courtney_hoy@comcast.com'
              ]

email_list_ml_bonding = ["tommy_wadelton@comcast.com"
                         ,"lauri_bednar@cable.comcast.com"
                         ,"pam_althoff@cable.comcast.com"
                         ,"john_salvatierra@cable.comcast.com"
                         ]

email_list_comcast_techops = ["lukas_briggs@comcast.com"
                           ,"tommy_wadelton@comcast.com"
                           ,"lauri_bednar@cable.comcast.com"
                           ,"omar_calderon@cable.comcast.com"
                           ,"lei_zhou@comcast.com"
                           ,"pam_althoff@cable.comcast.com"]

email_list_test = ["tommy_wadelton@comcast.com"]

email_two_email_test = ["tommy_wadelton@comcast.com"
                        ,"tommywadelton@outlook.com"]

email_list_california = ["tommy_wadelton@comcast.com"
                ,"larry_mendoza@cable.comcast.com"
                ,"matt_silvey@cable.comcast.com"]

email_list_pnw = ["tommy_wadelton@comcast.com"
                ,"richard_boyd2@cable.comcast.com"]

region_cal = 'Callifornia'
region_pnw_space = 'Pacific Northwest'
region_pnw = 'Pacific_Northwest'
Func_Data_Node_Analytics_string = "Node Analytics Reporting Tables Snapshot"
Func_Data_Power_Supply_string = "Power Supply Reporting Tables Snapshot"

server_287 = 'nfo-analytic287.oncomcast.com'
email_subject_287 = ' - nfo-analytic287'

server_1145 = 'nfo-report-1145.oncomcast.com'
email_subject_1145 = ' - nfo-report-1145'

#%% Func Updated

def Func_Updated(query, table_name, table_name_2, email_list, email_list_error):
    
    try:
        
        #connect to SQL Server    
    
        cnxn_str = ("Driver={ODBC Driver 17 for SQL Server};"
                    "Server=ontrcd-wc-p01;"
                    "Database=comtrac_dw;"
                    "UID=Tableau_NFO;"
                    "PWD=Tableaunf0;")
        
        cnxn = pyodbc.connect(cnxn_str)
        
        #Uses the query specified in the first argument for the function (i.e. Func_Updated(query, etc.))
        
        data = pd.read_sql(query,cnxn)
        
        cnxn.close()
        
        #The query is set up so that if the table updates as expected, there will be no rows in the data frame
        #if there are no rows, the it just prints "Update Successful"
        #if the data frame has a row, that means it didnt update correctly and will email you "need to update" and then the tables name
        
        def string():
            global y
            y = ''
            if data.shape[0] == 0:
                y = "Update Successful" + table_name
            elif data.shape[0] > 0:
                y = "Need to update:  " + table_name
    
        string()
        
        #if the data frame has a row, it sends an email saying it didnt update correctly
        

        
        def email_alert(subject, body, to):
            if data.shape[0] > 0:
                msg = EmailMessage()
                msg.set_content(body)
                msg['subject'] = subject
                msg['to'] = to
                
                user = "noreply@comcast.com"
                msg ['from'] = user
                
                server = smtplib.SMTP('mailrelay.comcast.com', 25)
                server.ehlo()
                server.starttls()
                server.ehlo()
                server.send_message(msg)
                server.quit()
                
            elif data.shape[0] == 0:
                pass
        
        #emails people in the specified email_list in the function 
        #Func_Updated(..., ...., email_list)
        
        #email_alert(email header, email text string (y), email list )
        for recipients in email_list:
            if __name__ == '__main__':
                email_alert("SQL Data Update Alert - Tableau_Weekly", y, recipients)
                
        if data.shape[0] == 0:
            ct = datetime.datetime.now()
            print(table_name_2 + ' updated correctly on ', ct)
        elif data.shape[0] > 0:
            ct = datetime.datetime.now()
            print(table_name_2 + ' - Email Sent:', ct)
            
    except:
        
        func_name = sys._getframe().f_code.co_name
        
        error_type, error_value, error_traceback = sys.exc_info()
        error_message = f"{error_type.__name__}: {str(error_value)}"
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
        

        
        msg = MIMEMultipart()
        #email header
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
        msg.attach(MIMEText(body, 'plain'))
        
        msg = EmailMessage()
        msg.set_content(body)
        msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
        
        if OOO == "N":
            msg['to'] = "tommy_wadelton@comcast.com"
        elif OOO == "Y":
            msg['to'] = email_list_error
        else:
            print("Unexpected response for OOO flag.")
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.ehlo()
        server.starttls()
        server.ehlo()
        server.send_message(msg)
        server.quit()
        
        print(f"Error occurred in {func_name}: {error_message}")
        print(f"\nError Email Sent for {func_name} Updated")

        
#%%Func Updated 287

def Func_Updated_287(query, table_name, table_name_2, email_list, email_list_error):
    
    try:
        
        #connect to SQL Server    
        cnxn_str = ("Driver={ODBC Driver 18 for SQL Server};"
                    "Server=nfo-analytic287.oncomcast.com;"
                    "Trusted_Connection=yes;")
        
        cnxn = pyodbc.connect(cnxn_str)
        
        #Uses the query specified in the first argument for the function (i.e. Func_Updated(query, etc.))
        
        data = pd.read_sql(query,cnxn)
        
        cnxn.close()
        
        #The query is set up so that if the table updates as expected, there will be no rows in the data frame
        #if there are no rows, the it just prints "Update Successful"
        #if the data frame has a row, that means it didnt update correctly and will email you "need to update" and then the tables name
        
        def string():
            global y
            y = ''
            if data.shape[0] == 0:
                y = "Update Successful"
            elif data.shape[0] > 0:
                y = "Need to update:  " + table_name
    
        string()
            
        #if the data frame has a row, it sends an email saying it didnt update correctly
        

        
        def email_alert(subject, body, to):
            if data.shape[0] > 0:
                msg = EmailMessage()
                msg.set_content(body)
                msg['subject'] = subject
                msg['to'] = to
                
                user = "noreply@comcast.com"
                msg ['from'] = user
                
                server = smtplib.SMTP('mailrelay.comcast.com', 25)
                server.ehlo()
                server.starttls()
                server.ehlo()
                server.send_message(msg)
                server.quit()
                
            elif data.shape[0] == 0:
                pass
        
        #emails people in the specified email_list in the function 
        #Func_Updated(..., ...., email_list)
        
        #email_alert(email header, email text string (y), email list )
        for recipients in email_list:
            if __name__ == '__main__':
                email_alert("FAILURE: PSNB_vs_Spatial_Trending", y, recipients)
                
        if data.shape[0] == 0:
            ct = datetime.datetime.now()
            print(table_name_2 + ' updated correctly on ', ct)
        elif data.shape[0] > 0:
            ct = datetime.datetime.now()
            print(table_name_2 + ' - Email Sent:', ct)
        
    except:
        
        func_name = sys._getframe().f_code.co_name
        
        error_type, error_value, error_traceback = sys.exc_info()
        error_message = f"{error_type.__name__}: {str(error_value)}"
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
        
        msg = MIMEMultipart()
        #email header
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
        msg.attach(MIMEText(body, 'plain'))
        
        msg = EmailMessage()
        msg.set_content(body)
        msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
        
        if OOO == "N":
            msg['to'] = "tommy_wadelton@comcast.com"
        elif OOO == "Y":
            msg['to'] = email_list_error
        else:
            print("Unexpected response for OOO flag.")
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.ehlo()
        server.starttls()
        server.ehlo()
        server.send_message(msg)
        server.quit()
        
        print(f"Error occurred in {func_name}: {error_message}")
        print(f"\nError Email Sent for {func_name} Updated")

#%% Daily Data Dump

def Func_Data(query, email_list, email_list_error):
    
    try:

        #connect to SQL Server    
        cnxn_str = ("Driver={ODBC Driver 17 for SQL Server};"
                    "Server=ontrcd-wc-p01;"
                    "Database=comtrac_dw;"
                    "UID=Tableau_NFO;"
                    "PWD=Tableaunf0;")
        
        cnxn = pyodbc.connect(cnxn_str)
        
        #run the query
        data = pd.read_sql(query,cnxn)
        
        cnxn.close()
            
        #email function
        #pulls in the current date information, can be used in the email header if you want
        #I had this for a different package, but didnt add it to this email    
        
        def date_function():
            timestr = time.strftime("%m%d%y")
            return timestr
        
        date = str(date_function())
        date = date[:2] + '/' + date[2:4] + '/' + date[4:6]
        
        
        #This is where you create the email with the information from the query
        

        
        #add the email of the people you want to include, if you want multiple recipients, it would look like this:
        #recipients = ['tommy_wadelton@comcast.com', 'another_email@comcast.com']     
            
        recipients = email_list
        emaillist = [elem.strip().split(',') for elem in recipients]
        msg = MIMEMultipart()
        #email header
        msg['Subject'] = "Ontrac_Combined_Completed_Orders - " + date
        
        #the email it is sent from, can be sent from your own email, but I use the Comcast No Reply
        #the html format below is so the email message is in a chart format    
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        #Add the data from the data frame into the email body, HTML format
        
        html = """\
            <html>
              <head></head>
              <body>
                  <table border="1">
                    <tr>
                      {headers}
                    </tr>
                    {rows}
                  </table>
              </body>
            </html>
            """.format(
                headers="\t".join([f'<th>{header}</th>' for header in data.columns]),
                rows="\n".join([
                    "<tr>" + 
                    "\t".join([
                        f'<td style="color: green;">{value}</td>' if value == 0 and index == 0 else
                       f'<td style="color: red;">{value}</td>' if value == 0 and index > 0 else
                       f'<td>{value}</td>' 
                       for i, value in enumerate(row)
                    ]) + 
                    "</tr>"
                    for index, row in data.iterrows()
                ])
            )
        
        part1 = MIMEText(html, 'html')
        msg.attach(part1)
        
        #The server Python uses to send the email
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.sendmail(msg['From'], emaillist , msg.as_string())
    
        
        ct = datetime.datetime.now()
        
        #Confirmation that the email sent, takes about 5 secs from getting the confirmation and receiving the email in Outlook
        
        print('Ontrac Combined Orders - Email Sent:', ct)
        
    except:
        
        func_name = sys._getframe().f_code.co_name
        
        error_type, error_value, error_traceback = sys.exc_info()
        error_message = f"{error_type.__name__}: {str(error_value)}"
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
        
        msg = MIMEMultipart()
        #email header
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
        msg.attach(MIMEText(body, 'plain'))
        
        msg = EmailMessage()
        msg.set_content(body)
        msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
        
        if OOO == "N":
            msg['to'] = "tommy_wadelton@comcast.com"
        elif OOO == "Y":
            msg['to'] = email_list_error
        else:
            print("Unexpected response for OOO flag.")
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.ehlo()
        server.starttls()
        server.ehlo()
        server.send_message(msg)
        server.quit()
        
        print(f"Error occurred in {func_name}: {error_message}")
        print(f"\nError Email Sent for {func_name} Updated")
    
#%% Node Analytics - Snapshot

def Func_Data_Node_Analytics(query, email_list, string, email_list_error):
    
    try:

        #connect to SQL Server    
        
        cnxn_str = ("Driver={ODBC Driver 18 for SQL Server};"
                    "Server=nfo-analytic287.oncomcast.com;"
                    "Trusted_Connection=yes;")
        
        cnxn = pyodbc.connect(cnxn_str)
        
        #run the query
        data = pd.read_sql(query,cnxn)
        data = data.astype(str)
        #data['Plant Stability Den - Total Accounts Day Level'] = data['Plant Stability Den - Total Accounts Day Level'].str.rstrip('.0')
        
        cnxn.close()
            
        #email function
        #pulls in the current date information, can be used in the email header if you want
        #I had this for a different package, but didnt add it to this email    
        
        def date_function():
            timestr = time.strftime("%m%d%y")
            return timestr
        
        date = str(date_function())
        date = date[:2] + '/' + date[2:4] + '/' + date[4:6]
        
        #add the email of the people you want to include, if you want multiple recipients, it would look like this:
        #recipients = ['tommy_wadelton@comcast.com', 'another_email@comcast.com']     

        emaillist = [email.strip() for email in email_list]
        msg = MIMEMultipart()
        #email header
        msg['Subject'] = string + "- " + date
        
        #the email it is sent from, can be sent from your own email, but I use the Comcast No Reply
        #the html format below is so the email message is in a chart format    
        
        user = "noreply@comcast.com"
        msg ['from'] = user
                
        headers = "".join([f'<th>{header}</th>' for header in data.columns])
        rows = "".join([
            "<tr>" + 
            "".join([
                f'<td style="color: red;">{value}</td>' if value == 0 else f'<td>{value}</td>' 
                for value in row
            ]) + 
            "</tr>"
            for index, row in data.iterrows()
        ])
        
        html = f"""
        <html>
          <head></head>
          <body>
              <table border="1">
                <tr>
                  {headers}
                </tr>
                {rows}
              </table>
          </body>
        </html>
        """

        part1 = MIMEText(html, 'html')
        msg.attach(part1)
        
        #The server Python uses to send the email
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.sendmail(msg['From'], emaillist , msg.as_string())
    
        
        ct = datetime.datetime.now()
        
        #Confirmation that the email sent, takes about 5 secs from getting the confirmation and receiving the email in Outlook
        
        print('Ontrac Combined Orders - Email Sent:', ct)
        
    except:

        func_name = sys._getframe().f_code.co_name
        
        error_type, error_value, error_traceback = sys.exc_info()
        error_message = f"{error_type.__name__}: {str(error_value)}"
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
        
        msg = MIMEMultipart()
        #email header
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
        msg.attach(MIMEText(body, 'plain'))
        
        msg = EmailMessage()
        msg.set_content(body)
        msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
        
        if OOO == "N":
            msg['to'] = "tommy_wadelton@comcast.com"
        elif OOO == "Y":
            msg['to'] = email_list_error
        else:
            print("Unexpected response for OOO flag.")
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.ehlo()
        server.starttls()
        server.ehlo()
        server.send_message(msg)
        server.quit()
        
        print(f"Error occurred in {func_name}: {error_message}")
        print(f"\nError Email Sent for {func_name} Updated")


#%% SQL Server Packages

def Func_SQL_Server_Jobs(server, server_subject, query, email_list, email_list_error):
    
        try:

            cnxn_str = ("Driver={ODBC Driver 17 for SQL Server};"
                        "Server=" + server + ";"
                        "Trusted_Connection=yes;")
            
            cnxn = pyodbc.connect(cnxn_str)
            
            #Query from SQL Server, no need for formatting, just paste as is from SQL Server
            # The triple " allow you to have a string be multiple lines in Python
                
            #run the query
            data = pd.read_sql(query,cnxn)
            
            #Bring in the SSIS excel data which has the package, table and dashboard link data
            
            df = pd.read_excel('C:\\Users\\adm_twadel816\\Documents\\SSIS_Excel.xlsx')
            
            #left join from the SQL data to the excel data
            df_combined = data.merge(df, on = 'Package', how = 'left')
            pd.set_option('display.max_columns', None)
                        
            table_names = df_combined['Table']
            table_names = table_names.dropna()
            
            query_results = []
            
            for table in table_names:
                query = f"""SELECT top 10 * FROM {table}"""
                result = pd.read_sql(query, cnxn)
                
                if result.empty:
                    query_results.append("N")
                else:
                    query_results.append("Y")
            
            cnxn.close()
            
            #df_combined is now your main data frame
            
            #email function
            #pulls in the current date information, can be used in the email header if you want
            #I had this for a different package, but didnt add it to this email    
            
            def date_function():
                timestr = time.strftime("%m%d%y")
                return timestr
            
            date = str(date_function())
            date = date[:2] + '/' + date[2:4] + '/' + date[4:6]

            #add the email of the people you want to include, if you want multiple recipients, it would look like this:
            #recipients = ['tommy_wadelton@comcast.com', 'another_email@comcast.com']     
                
            recipients = email_list
            emaillist = [elem.strip().split(',') for elem in recipients]
            msg = MIMEMultipart()
            #email header
            msg['Subject'] = "SQL Server Jobs Update" + server_subject
            
            #the email it is sent from, can be sent from your own email, but I use the Comcast No Reply
            #the html is to have a chart format
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            #Add the data from the data frame into the email body, HTML format
            
            html = """\
            <html>
              <head></head>
              <body>
                  {0}
              </body>
            </html>
            """.format(df_combined.to_html())
            
            part1 = MIMEText(html, 'html')
            msg.attach(part1)
            
            #The server Python uses to send the email
            
            server = smtplib.SMTP('mailrelay.comcast.com', 25)
            server.sendmail(msg['From'], emaillist , msg.as_string())
            
            ct = datetime.datetime.now()
            
            #Confirmation that the email sent, takes about 5 secs from getting the confirmation and receiving the email in Outlook
            
            print('SQL Server Jobs Email Sent:', ct)
        
        except:
            
            func_name = sys._getframe().f_code.co_name
            
            error_type, error_value, error_traceback = sys.exc_info()
            error_message = f"{error_type.__name__}: {str(error_value)}"
            
            def date_function():
                timestr = time.strftime("%m%d%Y")
                return timestr
            
            date_function()
            
            #This takes the date and puts it into the format I want
            #mm/dd/yyyy for the email
            
            date = str(date_function())
            date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]

            
            msg = MIMEMultipart()
            #email header
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
            msg.attach(MIMEText(body, 'plain'))
            
            msg = EmailMessage()
            msg.set_content(body)
            msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
            
            if OOO == "N":
                msg['to'] = "tommy_wadelton@comcast.com"
            elif OOO == "Y":
                msg['to'] = email_list_error
            else:
                print("Unexpected response for OOO flag.")
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            server = smtplib.SMTP('mailrelay.comcast.com', 25)
            server.ehlo()
            server.starttls()
            server.ehlo()
            server.send_message(msg)
            server.quit()
            
            print(f"Error occurred in {func_name}: {error_message}")
            print(f"\nError Email Sent for {func_name} Updated")

#%% SQL Server - 24 Hour + Jobs

def Func_SQL_Server_Jobs_24_Hours(server, query, server_subject, email_list, email_list_error):
        
        try:

            cnxn_str = ("Driver={ODBC Driver 17 for SQL Server};"
                        f"Server={server};"
                        "Trusted_Connection=yes;")
            
            cnxn = pyodbc.connect(cnxn_str)
            
            #Query from SQL Server, no need for formatting, just paste as is from SQL Server
            # The triple " allow you to have a string be multiple lines in Python
                
            #run the query
            data = pd.read_sql(query,cnxn)
            
            if data.shape[0] == 0:
                print("No Jobs have been detected running over 24 Hours for " + server_subject)
            
            elif data.shape[0] > 0:
            
                #Bring in the SSIS excel data which has the package, table and dashboard link data
                
                df = pd.read_excel('C:\\Users\\adm_twadel816\\Documents\\SSIS_Excel.xlsx')
                
                #left join from the SQL data to the excel data
                df_combined = data.merge(df, on = 'Package', how = 'left')
                
                #df_combined is now your main data frame
                
                def date_function():
                    timestr = time.strftime("%m%d%y")
                    return timestr
                
                date = str(date_function())
                date = date[:2] + '/' + date[2:4] + '/' + date[4:6]
                
                #add the email of the people you want to include, if you want multiple recipients, it would look like this:
                #recipients = ['tommy_wadelton@comcast.com', 'another_email@comcast.com']     
                    
                recipients = email_list
                emaillist = [elem.strip().split(',') for elem in recipients]
                msg = MIMEMultipart()
                #email header
                msg['Subject'] = "24+ Hour SQL Server Job Detected: " + server_subject
                
                #the email it is sent from, can be sent from your own email, but I use the Comcast No Reply
                #the html is to have a chart format
                
                user = "noreply@comcast.com"
                msg ['from'] = user
                
                #Add the data from the data frame into the email body, HTML format
                
                html = """\
                <html>
                  <head></head>
                  <body>
                      {0}
                  </body>
                </html>
                """.format(df_combined.to_html())
                
                part1 = MIMEText(html, 'html')
                msg.attach(part1)
                
                #The server Python uses to send the email
                
                server = smtplib.SMTP('mailrelay.comcast.com', 25)
                server.sendmail(msg['From'], emaillist , msg.as_string())
                
                ct = datetime.datetime.now()
                
                #Confirmation that the email sent, takes about 5 secs from getting the confirmation and receiving the email in Outlook
                
                print('24 Hour SQL Server Jobs Email Sent:', ct)
                
        except:
            
            func_name = sys._getframe().f_code.co_name
            
            error_type, error_value, error_traceback = sys.exc_info()
            error_message = f"{error_type.__name__}: {str(error_value)}"
            
            def date_function():
                timestr = time.strftime("%m%d%Y")
                return timestr
            
            date_function()
            
            #This takes the date and puts it into the format I want
            #mm/dd/yyyy for the email
            
            date = str(date_function())
            date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]

            
            msg = MIMEMultipart()
            #email header
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
            msg.attach(MIMEText(body, 'plain'))
            
            msg = EmailMessage()
            msg.set_content(body)
            msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
            
            if OOO == "N":
                msg['to'] = "tommy_wadelton@comcast.com"
            elif OOO == "Y":
                msg['to'] = email_list_error
            else:
                print("Unexpected response for OOO flag.")
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            server = smtplib.SMTP('mailrelay.comcast.com', 25)
            server.ehlo()
            server.starttls()
            server.ehlo()
            server.send_message(msg)
            server.quit()
            
            print(f"Error occurred in {func_name}: {error_message}")
            print(f"\nError Email Sent for {func_name} Updated")

        
#%% Spectra Backend Tables Updating

def Spectra_Updated(query, query2, email_list, email_list_error):
    
        try:
            
            user = u.user
            passw = p.passw
            
            #Connecting to Query Fabric
            #================ 
            server = {
            'host': 'query.comcast.com',
            'port': 9443
            }
            
            
            class enahncedAuth(trino.auth.BasicAuthentication):
                def __init__(
                    self,
                    username,
                    password
                ):
                    super().__init__(username,password)
            
                def set_http_session(self, http_session):
                    http_session = super().set_http_session(http_session)
                    return http_session
            
            _auth = enahncedAuth(
                user,
                passw
            )
            
            conn = trino.dbapi.connect(
                http_scheme='https',
                host=server['host'],
                port=server['port'],
                user=user,
                catalog='system',
                auth=_auth
            )
            
            data = pd.read_sql(query, conn)
            
            data2 = pd.read_sql(query2, conn)
            
            conn.close()
                
            #if the data frame has a row, it sends an email saying it didnt update correctly
            
            def email_alert(subject, body, to):
                if data.shape[0] > 0:
                    msg = MIMEMultipart()
                    msg['subject'] = subject
                    msg['to'] = to
                    msg['from'] = "noreply@comcast.com"
                    
                    html = """\
                    <html>
                      <head></head>
                      <body>
                          {0}
                      </body>
                    </html>
                    """.format(data2.to_html())
                    
                    part1 = MIMEText(html, 'html')
                    msg.attach(part1)
                    
                    # The server Python uses to send the email
                    server = smtplib.SMTP('mailrelay.comcast.com', 25)
                    server.ehlo()
                    server.starttls()
                    server.ehlo()
                    server.sendmail(msg['From'], to , msg.as_string())
                    server.quit()
                elif data.shape[0] == 0:
                    pass
                
            html = """\
            <html>
              <head></head>
              <body>
                  {0}
              </body>
            </html>
            """.format(data2.to_html())
            
            msg = MIMEMultipart()
            
            body = MIMEText(html, 'html')
            msg.attach(body)
            
            #email_list = ["tommy_wadelton@comcast.com", "luke_briggs@comcast.com"]
            
            def date_function():
                timestr = time.strftime("%m%d%y")
                return timestr
            
            date = str(date_function())
            date = date[:2] + '/' + date[2:4] + '/' + date[4:6]
            
            for recipients in email_list:
                if __name__ == '__main__':
                    email_alert("Spectra Table not updating - " + date, body, recipients)
        
            if data.shape[0] == 0:
                ct = datetime.datetime.now()
                print('Spectra Table updated correctly on ', ct)
            elif data.shape[0] > 0:
                ct = datetime.datetime.now()
                print(' - Email Sent:', ct)
                    
        except:
            
            func_name = sys._getframe().f_code.co_name
            
            error_type, error_value, error_traceback = sys.exc_info()
            error_message = f"{error_type.__name__}: {str(error_value)}"
            
            def date_function():
                timestr = time.strftime("%m%d%Y")
                return timestr
            
            date_function()
            
            #This takes the date and puts it into the format I want
            #mm/dd/yyyy for the email
            
            date = str(date_function())
            date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
            
            msg = MIMEMultipart()
            #email header
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
            msg.attach(MIMEText(body, 'plain'))
            
            msg = EmailMessage()
            msg.set_content(body)
            msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
            
            if OOO == "N":
                msg['to'] = "tommy_wadelton@comcast.com"
            elif OOO == "Y":
                msg['to'] = email_list_error
            else:
                print("Unexpected response for OOO flag.")
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            server = smtplib.SMTP('mailrelay.comcast.com', 25)
            server.ehlo()
            server.starttls()
            server.ehlo()
            server.send_message(msg)
            server.quit()
            
            print(f"Error occurred in {func_name}: {error_message}")
            print(f"\nError Email Sent for {func_name} Updated")
    
#%% IDLE Automation
    
def IDLE_MonthlyRpt(recipients, email_list_error):
    
    try:

        warnings.filterwarnings('ignore')
        
        #change my default directory for where I will write these files
        
        os.chdir('C:\\Users\\twadel816\\Documents')
        
        #connect to SQL Server    
        cnxn_str = ("Driver={ODBC Driver 17 for SQL Server};"
                    "Server=ontrcd-wc-p01;"
                    "Database=comtrac_dw;"
                    "UID=Tableau_NFO;"
                    "PWD=Tableaunf0;")
        
        cnxn = pyodbc.connect(cnxn_str)
        
        #brings in todays date and then uses that for the email, query parameters, etc.
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
        
        #this is used for the queries and puts the current date into the yyyy-mm format, and takes the previous month
        #i.e. if the current date is 5/23/2024, this part will return 2024-04
        
        trip_year = date[4:]
        trip_year_int = int(trip_year)
        trip_month = int(date[:2]) - 1
        trip_year_month = str(trip_year) + '-' + str(trip_month)
        
        #This is essentially doing the same thing as a 'decalare' statement that you would do in SQL
        #this part will return the 'start date' used in a few of the queries
        #i.e. if the current date is 5/23/2024, this part will return 2024-04-01
        
        if trip_month > 0 and trip_month < 10:
            global trip_start_date 
            trip_start_date =  date[4:] + '-0' + str(trip_month) + '-01'
        elif trip_month > 9:
            trip_start_date =  date[4:] + '-' + str(trip_month) + '-01'
        else:
            print("What do you mean, brother?!")
        
        #Same as above, but for the end date variable
        #This one is more complicated because I needed to handle dates with different numbers of days
        #so for the month numbers that are single digits, and end in 31 days, takes in the year, "-0" + month + 31
        #similar for single digit months ending in 30 days
        #double digit months ending in 31, etc.
        #Last one is handling February and when its a leap year 
        #trip_year_int % 4 == 0, this means the year divided by 4 has no remainer, then its a leap year, end in 29
        #trip_year_int % 4 != 0, not divisible by 4, so has a remainder
        
        if trip_month in (1,3,5,7,8):
            global trip_end_date 
            trip_end_date = date[4:] + '-0' + str(trip_month) + '-31'
        elif trip_month in (4,6,9):
            trip_end_date = date[4:] + '-0' + str(trip_month) + '-30'
        elif trip_month in (10,12):
            trip_end_date = date[4:] + '-' + str(trip_month) + '-31'
        elif trip_month == 11:
            trip_end_date = date[4:] + '-' + str(trip_month) + '-30'
        elif trip_month == 2 and trip_year_int % 4 == 0:
            trip_end_date = date[4:] + '-0' + str(trip_month) + '-29'
        elif trip_month == 2 and trip_year_int % 4 != 0:
            trip_end_date = date[4:] + '-0' + str(trip_month) + '-28'    
        else:
            print("What do you mean, brother?!")
        
        #Uses the query specified in the first argument for the function (i.e. Func_Updated(query, etc.))
        #Using the "?" character in a python query allows you to pass parameters into a query
        
        query_top_drivers = """
        select  * from
        (
        select TripYearMonth "Month*"
        ,Division
        ,Region
        ,Vehicle_NO
        ,FirstName
        ,LastName
        ,LOGIN_ID
        ,TotalIdleMinutes
        ,AvgIdleMinutes
        ,DaysWorked
        ,row_number() over (partition by region order by AvgIdleMinutes) Rank2
        from (
        select TripYearMonth
        ,Division
        ,case when REPLACE(Region,'Region','') in ('GREATER BOSTON', 'WESTERN NEW ENGLAND') then 'NEW ENGLAND'
        else REPLACE(Region,'Region','') end as Region
        ,Vehicle_NO
        ,FirstName
        ,LastName
        ,LOGIN_ID
        ,TotalIdleMinutes
        ,AvgIdleMinutes
        ,DaysWorked
        ,row_number() over (partition by region, vehicle_no order by AvgIdleMinutes desc) rownum1
        from (
        select convert(varchar,?) TripYearMonth
        ,case when DIVISION_Inv = 'CE' then 'CENTRAL'
                when DIVISION_Inv = 'NE' then 'NORTHEAST'
                when DIVISION_Inv = 'WE' then 'WEST'
              end Division
        ,case when region_inv in ('NORTH FL','SOUTH FL','SOUTHWEST FL','WEST PALM AREA') then 'FLORIDA' else REGION_INV end Region
        ,VEHICLE_NO Vehicle_NO
        ,A.FIRST_NAME FirstName
        ,SURNAME LastName
        ,B.LOGIN_ID
        ,SUM([Total Idle]) TotalIdleMinutes
        ,AVG([Total Idle]) AvgIdleMinutes
        ,COUNT(distinct trip_day) DaysWorked
        FROM comtrac_dw.dbo.tbl_Telematics_rpt_hist A
        left join comtrac_dw.dbo.ONTRACK_STAGE_SAP_V_ONTRAC B on A.ADDITION_DATA  = cast(B.PERNR as varchar)
        where trip_day between ? and ?
        and A.job_level = 'SUPERVISOR'
        and not (surname = 'SPARE' or surname = 'NEW')
        group by DIVISION_Inv
        ,case when region_inv in ('NORTH FL','SOUTH FL','SOUTHWEST FL','WEST PALM AREA') then 'FLORIDA' else REGION_INV end
        ,VEHICLE_NO
        ,A.FIRST_NAME
        ,B.LOGIN_ID
        ,SURNAME
        )x
        where Daysworked >= 10
        and TotalIdleMinutes > 0
        )xx
        where rownum1 = 1
        ) r
        where Rank2 <= 5
        """
        
        query_all = """
        select TripYearMonth
        ,Division
        ,case when REPLACE(Region,'Region','') in ('GREATER BOSTON', 'WESTERN NEW ENGLAND') then 'NEW ENGLAND'
        else REPLACE(Region,'Region','') end as Region
        ,Vehicle_NO
        ,FirstName
        ,LastName
        ,LOGIN_ID
        ,TotalIdleMinutes
        ,AvgIdleMinutes
        ,DaysWorked
        ,row_number() over (partition by case when REPLACE(Region,'Region','') in ('GREATER BOSTON', 'WESTERN NEW ENGLAND') then 'NEW ENGLAND'
        else REPLACE(Region,'Region','') end order by AvgIdleMinutes) Rank2
        from (
        select TripYearMonth
        ,Division
        ,REPLACE(Region,'Region','') Region
        ,Vehicle_NO
        ,FirstName
        ,LastName
        ,LOGIN_ID
        ,TotalIdleMinutes
        ,AvgIdleMinutes
        ,DaysWorked
        ,row_number() over (partition by region, vehicle_no order by AvgIdleMinutes desc) Rownum1
        from (
        select convert(varchar,?) TripYearMonth
        ,case when DIVISION_Inv = 'CE' then 'CENTRAL'
                when DIVISION_Inv = 'NE' then 'NORTHEAST'
                when DIVISION_Inv = 'WE' then 'WEST'
              end Division
        ,case when region_inv in ('NORTH FL','SOUTH FL','SOUTHWEST FL','WEST PALM AREA') then 'FLORIDA' else REGION_INV end Region
        ,VEHICLE_NO Vehicle_NO
        ,A.FIRST_NAME FirstName
        ,SURNAME LastName
        ,B.LOGIN_ID
        ,SUM([Total Idle]) TotalIdleMinutes
        ,AVG([Total Idle]) AvgIdleMinutes
        ,COUNT(distinct trip_day) DaysWorked
        FROM comtrac_dw.dbo.tbl_Telematics_rpt_hist A
        left join comtrac_dw.dbo.ONTRACK_STAGE_SAP_V_ONTRAC B on A.ADDITION_DATA  = cast(B.PERNR as varchar)
        where trip_day between ? and ?
        and A.job_level = 'SUPERVISOR'
        and not (surname = 'SPARE' or surname = 'NEW')
        group by DIVISION_Inv
        ,case when region_inv in ('NORTH FL','SOUTH FL','SOUTHWEST FL','WEST PALM AREA') then 'FLORIDA' else REGION_INV end
        ,VEHICLE_NO
        ,A.FIRST_NAME
        ,B.LOGIN_ID
        ,SURNAME
        )x
        where Daysworked >= 10
        and TotalIdleMinutes > 0
        )xx
        where rownum1 = 1
        """
        
        query_div_reg = """
        SELECT Division
        ,CASE WHEN Region IN ('WESTERN NEW ENGLAND', 'GREATER BOSTON') then 'NEW ENGLAND'
        else REGION end as Region
        ,cast(avg(AvgIdleMinutes) as int) AvgIdleMinutes
        FROM  [NFO_Analytics].dbo.IDLE_AvgMinutesByRegion 
        where tripyearmonth = ?												
        group by 
         Division
        ,CASE WHEN Region IN ('WESTERN NEW ENGLAND', 'GREATER BOSTON') then 'NEW ENGLAND'
        else REGION end
        order by Division
        """
        
        query_division = """
        SELECT Division
        ,AvgIdleMinutes
        FROM  [NFO_Analytics].dbo.IDLE_AvgMinutesByDivision
        where tripyearmonth = ?													
        order by division
        """
        
        query_totals_pivot = """
        select 
    	CONCAT(cast(left(TripYearMonth,4) as int), '-', FORMAT(cast(case when right(TripYearMonth,2) in ('-1',	'-2',	'-3',	'-4',	'-5',	'-6',	'-7',	'-8','-9') then right(TripYearMonth,1)
    	when right(TripYearMonth,2) in ('10', '11', '12') then right(TripYearMonth,2)
    	end as int), '00')) TripYearMonth
        ,Division
        ,case when Region = 'HOUSTON' then 'TEXAS'
        when Region in ('PORTLAND', 'SEATTLE') then 'PACIFIC NORTHWEST'
        when region in ('TWIN CITIES') then 'MIDWEST'
        WHEN Region in ('WESTERN NEW ENGLAND', 'GREATER BOSTON', 'NEW ENGLAND REGION') then 'NEW ENGLAND'
        else upper(Region) 
        end as Region
        ,cast(avg(AvgIdleMinutes) as int) AvgIdleMinutes
        from [NFO_Analytics].dbo.IDLE_AvgMinutesByRegion 
        group by 
        TripYearMonth
    	,cast(left(TripYearMonth,4) as int) 
    	,cast(case when right(TripYearMonth,2) in ('-1',	'-2',	'-3',	'-4',	'-5',	'-6',	'-7',	'-8','-9') then right(TripYearMonth,1)
    	when right(TripYearMonth,2) in ('10', '11', '12') then right(TripYearMonth,2)
    	end as int) 
        ,Division
        ,case when Region = 'HOUSTON' then 'TEXAS'
        when Region in ('PORTLAND', 'SEATTLE') then 'PACIFIC NORTHWEST'
        when region in ('TWIN CITIES') then 'MIDWEST'
        WHEN Region in ('WESTERN NEW ENGLAND', 'GREATER BOSTON', 'NEW ENGLAND REGION') then 'NEW ENGLAND'
        else upper(Region) 
        end
    	,CONCAT(cast(left(TripYearMonth,4) as int), '-', FORMAT(cast(case when right(TripYearMonth,2) in ('-1',	'-2',	'-3',	'-4',	'-5',	'-6',	'-7',	'-8','-9') then right(TripYearMonth,1)
    	when right(TripYearMonth,2) in ('10', '11', '12') then right(TripYearMonth,2)
    	end as int), '00'))
        order by 
    	CONCAT(cast(left(TripYearMonth,4) as int), '-', FORMAT(cast(case when right(TripYearMonth,2) in ('-1',	'-2',	'-3',	'-4',	'-5',	'-6',	'-7',	'-8','-9') then right(TripYearMonth,1)
    	when right(TripYearMonth,2) in ('10', '11', '12') then right(TripYearMonth,2)
    	end as int), '00')) desc
        """
        
        Current_Year_Data = """
            select case when division is null and region is null 
        	then 'GRAND TOTAL'
        	else division end as Division
        	,case when region is null and division = 'CENTRAL' then 'CENTRAL TOTAL'
        	when region is null and division = 'NORTHEAST' then 'NORTHEAST TOTAL'
        	when region is null and division = 'WEST' then 'WEST TOTAL'
        	when region is null and division is null then 'GRAND TOTAL'
        	else region 
        	end as Region
        	,"2024 Average"
        	from
        	(
        	SELECT 
        	division
        	,case when region = 'HOUSTON' then 'TEXAS'
        	when region = 'PORTLAND' or region = 'SEATTLE' OR REGION = 'PACIFIC NORTHWEST' then 'PACIFIC NORTHWEST'
        	WHEN region = 'TWIN CITIES' THEN 'MIDWEST'
        	ELSE region
        	END AS region
        	,cast(avg(AvgIdleMinutes) as int) as "2024 Average"
            FROM  [NFO_Analytics].dbo.IDLE_AvgMinutesByRegion 
            where left(tripyearmonth,4) = left(cast(getdate() as date),4)
            
        	group by rollup 
        	(division
        	,case when region = 'HOUSTON' then 'TEXAS'
        	when region = 'PORTLAND' or region = 'SEATTLE' OR REGION = 'PACIFIC NORTHWEST' then 'PACIFIC NORTHWEST'
        	WHEN region = 'TWIN CITIES' THEN 'MIDWEST'
        	ELSE region
        	END)
        	) a
        """
    
        # Paste the Excel data here
        Year_Data_Static = """Division,Region,2020 Average,2021 Average,2022 Average,2023 Average
        CENTRAL,BIG SOUTH,94,78,85,96
        CENTRAL,CHICAGO,63,42,32,35
        CENTRAL,FLORIDA,101,87,87,95
        CENTRAL,HEARTLAND,115,66,65,67
        CENTRAL TOTAL,CENTRAL TOTAL,94,69,69,71
        NORTHEAST,BELTWAY,137,121,110,113
        NORTHEAST,FREEDOM,116,108,94,94
        NORTHEAST,GREATER BOSTON,66,46,41,57
        NORTHEAST,KEYSTONE,94,86,85,76
        NORTHEAST,WESTERN NEW ENGLAND,95,93,87,83
        NORTHEAST TOTAL,NORTHEAST TOTAL,132,126,122,126
        WEST,CALIFORNIA,119,110,113,112
        WEST,MIDWEST,101,97,79,82
        WEST,MOUNTAIN WEST,80,78,71,70
        WEST,PACIFIC NORTHWEST,84,85,90,70
        WEST,TEXAS,100,86,83,84
        WEST TOTAL,WEST TOTAL,94,94,93,85
        GRAND TOTAL,GRAND TOTAL,116,104,95,99
        """
    
        # Create DataFrame to be used later in the CSVs and Excel
        
        Year_Data = pd.read_csv(io.StringIO(Year_Data_Static), delimiter=',')
        
        Current_Year_Data = pd.read_sql(Current_Year_Data,cnxn)
        
        Current_Year_Data = Current_Year_Data['2024 Average']
        
        data = pd.read_sql(query_top_drivers,cnxn, params=(trip_year_month,trip_start_date, trip_end_date,))
        
        data2 = pd.read_sql(query_all,cnxn, params=(trip_year_month,trip_start_date, trip_end_date,))
        
        data3 = pd.read_sql(query_div_reg,cnxn, params=(trip_year_month,))
        
        data4 = pd.read_sql(query_division,cnxn, params=(trip_year_month,))
        
        data5_df = pd.read_sql(query_totals_pivot, cnxn)
        
        division_averages = data5_df.groupby(['TripYearMonth', 'Division'])['AvgIdleMinutes'].mean().reset_index()
        division_averages['Region'] = ''
        
        # Calculate Grand totals for each TripYearMonth
        grand_totals = division_averages.groupby('TripYearMonth')['AvgIdleMinutes'].mean().reset_index()
        grand_totals['Division'] = 'ZGrand Total'
        grand_totals['Region'] = ''
        grand_totals = grand_totals.rename(columns={'AvgIdleMinutes': 'AvgIdleMinutes'})
        
        # Concatenate division averages and grand totals to the original DataFrame
        pd.set_option('display.max_rows', None)
        data5_with_totals = pd.concat([data5_df, division_averages, grand_totals])
        
        pivot_table = pd.pivot_table(data5_with_totals, values='AvgIdleMinutes', index=['Division', 'Region'], columns='TripYearMonth', aggfunc='mean')
        
        # Concatenate division averages and grand totals to the original DataFrame
        #Close the connection to SQL
        
        cnxn.close()
        
        # Save each DataFrame to its own CSV file
        Year_Data.to_csv('Year_Data_Static.csv', index=False)
        Current_Year_Data.to_csv('Current_Year_Data.csv', index = False)
        data.to_csv('Top_Drivers.csv', index=False)
        data2.to_csv('All_Data.csv', index=False)
        data3.to_csv('Division_Region.csv', index=False)
        data4.to_csv('Division.csv', index=False)
        data5_df.to_csv('Totals_Pivot.csv', index=False)
        pivot_table.to_csv('Pivot_Table.csv', index=True)
    
        #print("Data written into individual CSV files!")
        
        #Email section of the script

                
        emaillist = [elem.strip().split(',') for elem in recipients]
        msg = MIMEMultipart()
        #email header
        msg['Subject'] = "IDLE Monthly Report - " + date_email
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        body = "Hi,\n\nHere is the updated IDLE Monthly Report, as of " + date_email + ".\n\nThanks,\n\nEnterprise BI Data Products & Governance"
        msg.attach(MIMEText(body, 'plain'))
        
        #Create the excel sheet
        excel_file_path = "IDLE_MonthlyRpt.xlsx"
               
        csv_files_sheets = {
            'Pivot_Table.csv': ('Overall Stats', 5, 1), #Should be B6   
            'Year_Data_Static.csv': ('Overall Stats', 26, 1),  # B27 corresponds to row=1 (0-indexed), col=2 (0-indexed)
            'Current_Year_Data.csv': ('Overall Stats', 26, 7),
            'Top_Drivers.csv': ('Top Drivers - Month', 3, 1),
            'All_Data.csv': ('All', 0, 0),
            'Division_Region.csv': ('Region-Division', 2, 0),
            'Division.csv': ('Region-Division', 2, 4)   
        }
        
        # insert the data from the CSVs into the excel sheet
        
        with pd.ExcelWriter(excel_file_path, engine='openpyxl') as writer:
            for csv_file, (sheet_name, start_row, start_col) in csv_files_sheets.items():
                df = pd.read_csv(csv_file)
                df.to_excel(writer, index=False, sheet_name=sheet_name, startrow=start_row, startcol=start_col)

        
        wb = load_workbook(excel_file_path)
        
        ws1 = wb['Overall Stats']
        ws2 = wb['Top Drivers - Month']
        #ws3 = wb['All']
        ws4 = wb['Region-Division']
    
        #Overall Stats    
        ws1['B1'] = "Average Minutes per month - Trend"
        ws1['B2'] = "By Region"
        ws1['B3'] = trip_year_month
        ws1['B7'] = "CENTRAL TOTAL"
        ws1['B12'] = "NORTHEAST TOTAL"
        ws1['B18'] = "WEST TOTAL"
        ws1['B24'] = "GRAND TOTAL"
    
        #Top Drivers - Month
        ws2['A1'] = "EVERY MINUTE MATTERS MONTHLY RECOGNITION"
        ws2['A2'] = "Top Drivers Report"
        ws2['I1'] = "*Month is based on calendar month not fiscal month"
        
        #Region-Division
        ws4['A1'] = "Region Div"
        
        #Adjusting the column width automatically
        
        def adjust_column_widths(ws, manual_columns):
            for column in ws.columns:
                column_letter = column[0].column_letter  # Get the column name
                if column_letter in manual_columns:
                    continue  # Skip manual columns
        
                max_length = 0
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(cell.value)
                    except:
                        pass
                adjusted_width = (max_length + 2)
                ws.column_dimensions[column_letter].width = adjusted_width
        
        # Manually adjust column widths for each worksheet, mainly to handle when there is a title/text in a cell
        #..to not make the cell way to wide, just for aesthetics
        
        for sheet in wb.sheetnames:
            ws = wb[sheet]
            if ws.title == 'Overall Stats':
                # Manually adjust specified columns for 'Overall Stats'
                ws.column_dimensions['B'].width = 15
                adjust_column_widths(ws, {'B'})
            elif ws.title == 'Overall Stats':
                # Manually adjust specified columns for 'Overall Stats'
                ws.column_dimensions['B'].width = 23
                adjust_column_widths(ws, {'C'})
            elif ws.title == 'Top Drivers - Month':
                # Manually adjust specified columns for 'Top Drivers - Month'
                ws.column_dimensions['A'].width = 12
                adjust_column_widths(ws, {'A'})
            elif ws.title == 'Top Drivers - Month':
                # Manually adjust specified columns for 'Top Drivers - Month'
                ws.column_dimensions['I'].width = 16
                adjust_column_widths(ws, {'I'})
            else:
                # Automatically adjust all columns for other sheets
                adjust_column_widths(ws, {})
        
        #merge and center cells for the pivot table
        
        ws1.merge_cells('B7:C7')
        ws1 = wb['Overall Stats']
        ws1['B7'].alignment = Alignment(horizontal='center', vertical='center')
        ws1.merge_cells('B12:C12')
        ws1['B12'].alignment = Alignment(horizontal='center', vertical='center')
        ws1.merge_cells('B18:C18')
        ws1['B18'].alignment = Alignment(horizontal='center', vertical='center')
        ws1.merge_cells('B24:C24')
        ws1['B24'].alignment = Alignment(horizontal='center', vertical='center')
        
        ws1['B32'].alignment = Alignment(horizontal='center', vertical='center')
        ws1.merge_cells('B32:C32')
        ws1['B38'].alignment = Alignment(horizontal='center', vertical='center')
        ws1.merge_cells('B38:C38')
        ws1['B44'].alignment = Alignment(horizontal='center', vertical='center')
        ws1.merge_cells('B44:C44')
        ws1['B45'].alignment = Alignment(horizontal='center', vertical='center')
        ws1.merge_cells('B45:C45')
        
        # Save the workbook
        
        wb.save(excel_file_path)  
        
        # Attach the Excel file to the email and send the email
        try:
            with open(excel_file_path, "rb") as attachment:
                part = MIMEBase('application', 'octet-stream')
                part.set_payload(attachment.read())
                encoders.encode_base64(part)
                part.add_header('Content-Disposition', f"attachment; filename={excel_file_path}")
                msg.attach(part)
                #print(f"Attached {excel_file_path}")
        except Exception as e:
            print(f"Failed to attach file {excel_file_path}: {e}")
            exit(1)
    
        # Connect to SMTP server and send the email
        try:
            server = smtplib.SMTP('mailrelay.comcast.com', 25)
            server.sendmail(msg['From'], emaillist, msg.as_string())
            server.quit()
            print("IDLE Email sent successfully." + date_email)
        except Exception as e:
            print(f"Failed to send email: {e}")
            

    except:
        
        func_name = sys._getframe().f_code.co_name
        
        error_type, error_value, error_traceback = sys.exc_info()
        error_message = f"{error_type.__name__}: {str(error_value)}"
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
        
        msg = MIMEMultipart()
        #email header
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
        msg.attach(MIMEText(body, 'plain'))
        
        msg = EmailMessage()
        msg.set_content(body)
        msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
        
        if OOO == "N":
            msg['to'] = "tommy_wadelton@comcast.com"
        elif OOO == "Y":
            msg['to'] = email_list_error
        else:
            print("Unexpected response for OOO flag.")
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.ehlo()
        server.starttls()
        server.ehlo()
        server.send_message(msg)
        server.quit()
        
        print(f"Error occurred in {func_name}: {error_message}")
        print(f"\nError Email Sent for {func_name} Updated")
        
#%% Plant Stability

def Plant_Stability(query, region, region_space, email_list, email_list_error):
    
        try:            
            user = u.user
            passw = p.passw
            
            #Connecting to Query Fabric
            #================ 
            server = {
            'host': 'query.comcast.com',
            'port': 9443
            }
            
            
            class enahncedAuth(trino.auth.BasicAuthentication):
                def __init__(
                    self,
                    username,
                    password
                ):
                    super().__init__(username,password)
            
                def set_http_session(self, http_session):
                    http_session = super().set_http_session(http_session)
                    return http_session
            
            _auth = enahncedAuth(
                user,
                passw
            )
            
            conn = trino.dbapi.connect(
                http_scheme='https',
                host=server['host'],
                port=server['port'],
                user=user,
                catalog='system',
                auth=_auth
            )
            
            #print('Running the QF Query')
                
            df_cal = pd.read_sql(query, conn)
            #df_pnw = pd.read_sql(pnw_query, conn)
            
            #California
            
            def date_function():
                timestr = time.strftime("%m%d%Y")
                return timestr
            
            date_function()
            
            #This takes the date and puts it into the format I want
            #mm/dd/yyyy for the email
            
            date = str(date_function())
            date_email = date[:2] + '.' + date[2:4] + '.' + date[4:] #+ str('.xlsx')
            
            excel_file_path_cal = "Plant_Stability_" + str(region) + "_" + date_email + ".xlsx"
            df_cal.to_excel(excel_file_path_cal, index=False)
            #print(str(region) + " Data Written to Excel\n")
                    
            emaillist = email_list
            msg = MIMEMultipart()
            #email header
            msg['Subject'] = "Plant Stability - " + str(region_space) + " " + date_email
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            body = "Hi,\n\nHere is the weekly Plant Stability Report, as of " + date_email + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
            msg.attach(MIMEText(body, 'plain'))
            
            #Create the excel sheet    
            
            # Attach the Excel file to the email and send the email
            try:
                with open(excel_file_path_cal, "rb") as attachment:
                    part = MIMEBase('application', 'octet-stream')
                    part.set_payload(attachment.read())
                    encoders.encode_base64(part)
                    part.add_header('Content-Disposition', f"attachment; filename={excel_file_path_cal}")
                    msg.attach(part)
                    #print(f"Attached {excel_file_path}")
            except Exception as e:
                print(f"Failed to attach file {excel_file_path_cal}: {e}")
                exit(1)
        
            # Connect to SMTP server and send the email
            try:
                server = smtplib.SMTP('mailrelay.comcast.com', 25)
                server.sendmail(msg['From'], emaillist, msg.as_string())
                server.quit()
                print(str(region) + " Plant Stability Email sent successfully on " + date_email)
            except Exception as e:
                print(f"Failed to send email: {e}")
                
    
        except:
            
            func_name = sys._getframe().f_code.co_name
            
            error_type, error_value, error_traceback = sys.exc_info()
            error_message = f"{error_type.__name__}: {str(error_value)}"
            
            def date_function():
                timestr = time.strftime("%m%d%Y")
                return timestr
            
            date_function()
            
            #This takes the date and puts it into the format I want
            #mm/dd/yyyy for the email
            
            date = str(date_function())
            date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
        
            
            msg = MIMEMultipart()
            #email header
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
            msg.attach(MIMEText(body, 'plain'))
            
            msg = EmailMessage()
            msg.set_content(body)
            msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
            
            if OOO == "N":
                msg['to'] = "tommy_wadelton@comcast.com"
            elif OOO == "Y":
                msg['to'] = email_list_error
            else:
                print("Unexpected response for OOO flag.")
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            server = smtplib.SMTP('mailrelay.comcast.com', 25)
            server.ehlo()
            server.starttls()
            server.ehlo()
            server.send_message(msg)
            server.quit()
            
            print(f"Error occurred in {func_name}: {error_message}")
            print(f"\nError Email Sent for {func_name} Updated")

            
#%% ML Bonding

def ML_Bonding(email_list, email_list_error):
    
    try:
        cnxn_str = ("Driver={ODBC Driver 17 for SQL Server};"
         "Server=ontrcd-wc-p01;"
         "Database=comtrac_dw;"
         "UID=Tableau_NFO;"
         "PWD=Tableaunf0;")
         
        cnxn = pyodbc.connect(cnxn_str)
        
        query = """
        Select CompleteDateDT
        ,sum(Null_Eventkey) Null_Eventkey
        ,sum(EventKey) EventKey
        ,cast(sum(Null_EventKey) as decimal(10,2)) / cast(sum(Null_Eventkey) + sum(Eventkey) as decimal(10,2)) as Null_Percentage
        ,case when cast(sum(Null_EventKey) as decimal(10,2)) / cast(sum(Null_Eventkey) + sum(Eventkey) as decimal(10,2))  >.9 then 1 else 0 end as Null_Flag
        FROM
        (
        select completedatedt
        , case when eventkey is Null then count(*) else 0 end as Null_Eventkey
        , case when eventkey is NOT Null then count(*) else 0 end as Eventkey
        from [comtrac_dw].[dbo].[PowerbondHousebox_Detail] p
        join [comtrac_dw].[Reporting].vw_Ontrac_Combined_Orders o
            on p.workordernumber = o.workordernumber collate SQL_Latin1_General_CP1_CS_AS
        where o.completedatedt between getdate() -10 and getdate() - 3
        group by completedatedt, eventkey
        ) a
        group by CompleteDateDT
        having case when cast(sum(Null_EventKey) as decimal(10,2)) / cast(sum(Null_Eventkey) + sum(Eventkey) as decimal(10,2))  >.9 then 1 else 0 end = 1
        order by CompleteDateDt desc
        """
        
        data = pd.read_sql(query,cnxn)
        
        #print(data)
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
            
        def string():
            global y
            y = ''
            if data.shape[0] == 0:
                y = "No Outage Detected for the ML Bonding Source"
            elif data.shape[0] > 0:
                y = "Outage Detected for the ML Bonding Source " + date_email
        
        string()
            
        #if the data frame has a row, it sends an email saying it didnt update correctly
    
        if data.shape[0] > 0:
            msg = EmailMessage()
            msg.set_content(y)
            msg['subject'] = y
            msg['to'] = email_list
            
            user = "noreply@comcast.com"
            msg ['from'] = user
            
            html = """\
            <html>
              <head></head>
              <body>
                  {0}
              </body>
            </html>
            """.format(data.to_html())
    
            msg.set_content('Outage Detected.')
            msg.add_alternative(html, subtype='html')
            
            server = smtplib.SMTP('mailrelay.comcast.com', 25)
            server.ehlo()
            server.starttls()
            server.ehlo()
            server.send_message(msg)
            server.quit()
            
        elif data.shape[0] == 0:
            pass
        
        if data.shape[0] == 0:
            ct = datetime.datetime.now()
            print("ML Bonding Updated correctly on ", ct)
        elif data.shape[0] > 0:
            ct = datetime.datetime.now()
            print('ML Bonding - Email Sent:', ct)
        
    except:
        
        func_name = sys._getframe().f_code.co_name
        
        error_type, error_value, error_traceback = sys.exc_info()
        error_message = f"{error_type.__name__}: {str(error_value)}"
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
    
        
        msg = MIMEMultipart()
        #email header
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
        msg.attach(MIMEText(body, 'plain'))
        
        msg = EmailMessage()
        msg.set_content(body)
        msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
        
        if OOO == "N":
            msg['to'] = "tommy_wadelton@comcast.com"
        elif OOO == "Y":
            msg['to'] = email_list_error
        else:
            print("Unexpected response for OOO flag.")
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.ehlo()
        server.starttls()
        server.ehlo()
        server.send_message(msg)
        server.quit()
        
        print(f"Error occurred in {func_name}: {error_message}")
        print(f"\nError Email Sent for {func_name} Updated")
        
#%% DX_DL_Comcast_Techops

def dx_dl_comcast_techops(email_list, email_list_error):
    
    try:
    
        xpm_scorecard_all_in = """
        select 
        fiscal_month_end
        ,avg(ANS_Score) ANSScore
        ,sum(gmc_num) gmc_num
        ,sum(gmc_den) gmc_den
        ,avg(avg_xit) avg_xit
        ,sum(red_node_num) red_node_num
        ,sum(red_node_den) red_node_den
        ,sum(nps_num) nps_num
        ,sum(nps_den) nps_den
         from minio.dx_dl_comcast_techops.xpm_scorecard_all_in
         group by 1
         order by 1 desc
         limit 12"""
        
        failure_mode_repeat = """
        select fiscal_month_end
        ,sum(repeat_num) repeat_num
        ,sum(repeat_den) repeat_den
        from minio.dx_dl_comcast_techops.failure_mode_repeat
        group by fiscal_month_end
        order by fiscal_month_end desc
        limit 12"""
        
        failure_mode_sla= """
        select fiscal_month_end
        ,sum(compliance_numerator) compliance_numerator
        ,sum(compliance_denominator) compliance_denominator
        from minio.dx_dl_comcast_techops.failure_mode_sla
        group by 1
        order by 1 desc
        limit 12"""
        
        power_saves = """
        select
        fiscal_month_end
        ,sum(loss_of_communication_flag) loss_of_communication_flag
        ,sum(end_of_discharge_flag) end_of_discharge_flag
        ,sum(power_saves_numerator) power_saves_numerator
        ,sum(power_saves_denominator) power_saves_denominator
        from minio.dx_dl_comcast_techops.power_saves
        group by 1
        order by 1 desc
        limit 12"""
        
        power_supply_normal_status = """
        select fiscal_month_end
        ,sum(count_normal_status) count_normal_status
        ,sum(count_all_status) count_all_status
        from minio.dx_dl_comcast_techops.power_supply_normal_status
        group by 1
        order by 1 desc
        limit 12"""
        
        ans_rns_combined_daily = """
        select fiscalmonthend
        ,sum(node_red) node_red
        ,sum(node_measured_total) node_measured_total
        ,sum(reportingperiodnodescore) reportingperiodnodescore
        ,sum(anscore_max) anscore_max
        ,sum(sh_contribution) sh_contribution
        ,sum(mh_contribution) mh_contribution
        from minio.dx_dl_comcast_techops.ans_rns_combined_daily
        group by 1
        order by 1 desc
        limit 12"""
        
        red_node_agg = """
        select
        fiscalmonthend
        ,sum(count_distinct_node) count_distinct_node
        ,sum(node_measured_total) node_measured_total
        ,sum(node_green) node_green
        ,sum(node_yellow) node_yellow
        ,sum(node_red) node_red
        from minio.dx_dl_comcast_techops.red_node_agg
        group by 1
        order by 1 desc
        limit 12"""
        
        xpm_scorecard_power_supply_aggregate = """
        select
        fiscal_month_end
        ,sum(power_supply_score) power_supply_score
        ,sum(n2psa_num) n2psa_num
        ,sum(n2psa_den) n2psa_den
        ,sum(ps_normal_status_num) ps_normal_status_num
        ,sum(ps_alert_status_num) ps_alert_status_num
        ,sum(ps_offline_status_num) ps_offline_status_num
        ,sum(ps_status_den) ps_status_den
        ,sum(outage_n2psa_num) outage_n2psa_num
        ,sum(outage_n2psa_den) outage_n2psa_den
        from minio.dx_dl_comcast_techops.xpm_scorecard_power_supply_aggregate
        group by 1
        order by 1 desc
        limit 12"""
        
        xpm_scorecard_rtm = """
        select
        fiscalmonthend
        ,sum(nps_num) nps_num
        ,sum(nps_den) nps_den
        from minio.dx_dl_comcast_techops.xpm_scorecard_rtm
        group by 1
        order by 1 desc
        limit 12"""
        
        power_supply_cleanup_daily_snapshot = """
        select
        "date"
        ,sum(missing_egisname_num) missing_egisname_num
        ,sum(missing_egisname_den) missing_egisname_den
        ,sum(in_psnb_not_in_spatial_num) in_psnb_not_in_spatial_num
        ,sum(in_psnb_not_in_spatial_den) in_psnb_not_in_spatial_den
        ,sum(in_spatial_not_in_psnb_num) in_spatial_not_in_psnb_num
        ,sum(in_spatial_not_in_psnb_den) in_spatial_not_in_psnb_den
        from minio.dx_dl_comcast_techops.power_supply_cleanup_daily_snapshot
        group by 1
        order by 1 desc
        limit 100"""
        
        queries = [xpm_scorecard_all_in
                   , failure_mode_repeat
                   , failure_mode_sla
                   , power_saves
                   , power_supply_normal_status
                   #, ans_rns_combined_daily
                   , red_node_agg
                   , xpm_scorecard_power_supply_aggregate
                   , xpm_scorecard_rtm
                   , power_supply_cleanup_daily_snapshot]
        
        
        for query in queries:
            user = st_u.user
            passw = st_p.passw
            
            #Connecting to Query Fabric
            #================ 
            server = {
            'host': 'query.comcast.com',
            'port': 9443
            }
            
            
            class enahncedAuth(trino.auth.BasicAuthentication):
                def __init__(
                    self,
                    username,
                    password
                ):
                    super().__init__(username,password)
            
                def set_http_session(self, http_session):
                    http_session = super().set_http_session(http_session)
                    return http_session
            
            _auth = enahncedAuth(
                user,
                passw
            )
            
            conn = trino.dbapi.connect(
                http_scheme='https',
                host=server['host'],
                port=server['port'],
                user=user,
                catalog='system',
                auth=_auth
            )
            
            data = pd.read_sql(query, conn)
            
            conn.close()
            
            data_null = data.isnull().any().any()
            
            if data_null == True:
            
                print(data)
                
                import re
                
                def extract_full_table_name(query):
                    # Regular expression to match the full table name after 'FROM' or 'JOIN'
                    match = re.search(r"(?:FROM|JOIN)\s+([`'\[]?[\w\.\-`'\[]+[\]`'\]]?)", query, re.IGNORECASE)
                    if match:
                        return match.group(1).replace("`", "").replace("'", "").replace("[", "").replace("]", "").strip()
                    return None
                
                # Example usage
                table_name = extract_full_table_name(query)
                    
                print(table_name + ": " + str(data_null))
    
                subject = "Null Data detected for " + table_name
                to = 'tommy_wadelton@comcast.com'
        
                msg = MIMEMultipart()
                msg['subject'] = subject
                msg['To'] = ', '.join(email_list)  # Join emails with commas
                msg['from'] = "noreply@comcast.com"
                
                html = """\
                <html>
                  <head></head>
                  <body>
                      {0}
                  </body>
                </html>
                """.format(data.to_html())
                
                part1 = MIMEText(html, 'html')
                msg.attach(part1)
                
                # The server Python uses to send the email
                server = smtplib.SMTP('mailrelay.comcast.com', 25)
                server.ehlo()
                server.starttls()
                server.ehlo()
                server.sendmail(msg['From'], to , msg.as_string())
                server.quit()
                print("Email sent.")
            
            else:
                pass
        
        tables = ['xpm_scorecard_all_in'
                  , 'failure_mode_repeat'
                  #,'ans_rns_combined_daily'
                  ,'failure_mode_sla'
                  ,'power_saves'
                  ,'power_supply_cleanup_daily_snapshot'
                  ,'power_supply_normal_status'
                  ,'red_node_agg'
                  ,'xpm_scorecard_power_supply_aggregate'
                  ,'xpm_scorecard_rtm']
        
        query_template = """select * from minio.dx_dl_comcast_techops.{} limit 10"""
        
        for table in tables:
            query = query_template.format(table)
        
            data = pd.read_sql(query, conn)
            
            conn.close()
            
            subject = table + " is null"
            
            if data.shape[0] == 0:
                msg = MIMEMultipart()
                msg['subject'] = subject
                msg['To'] = ', '.join(email_list)  # Join emails with commas
                msg['from'] = "noreply@comcast.com"
                
                html = """\
                <html>
                  <head></head>
                  <body>
                      {0}
                  </body>
                </html>
                """.format(data.to_html())
                
                part1 = MIMEText(html, 'html')
                msg.attach(part1)
                
                # The server Python uses to send the email
                server = smtplib.SMTP('mailrelay.comcast.com', 25)
                server.ehlo()
                server.starttls()
                server.ehlo()
                server.sendmail(msg['From'], to , msg.as_string())
                server.quit()
                print("Email sent: " + table + " is null")
            elif data.shape[0] > 0:
                pass
            
        ct = datetime.datetime.now()
        print('The dx_dl_comcast_techops function ran on:', ct)
        
    except:
        
        func_name = sys._getframe().f_code.co_name
        
        error_type, error_value, error_traceback = sys.exc_info()
        error_message = f"{error_type.__name__}: {str(error_value)}"
        
        def date_function():
            timestr = time.strftime("%m%d%Y")
            return timestr
        
        date_function()
        
        #This takes the date and puts it into the format I want
        #mm/dd/yyyy for the email
        
        date = str(date_function())
        date_email = date[:2] + '/' + date[2:4] + '/' + date[4:]
    
        
        msg = MIMEMultipart()
        #email header
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        body = f"Hi,\n\nAn error for the {func_name} Script was detected on  " + date_email + f"\n\n{error_message}" + ".\n\nThanks\n\nTommy Wadelton\nSr. Data Engineer\nEBI Reporting | XGIE"
        msg.attach(MIMEText(body, 'plain'))
        
        msg = EmailMessage()
        msg.set_content(body)
        msg['Subject'] = f"Python Script Error - {func_name} on " + date_email
        
        if OOO == "N":
            msg['to'] = "tommy_wadelton@comcast.com"
        elif OOO == "Y":
            msg['To'] = ', '.join(email_list_error)  # Join emails with commas
        else:
            print("Unexpected response for OOO flag.")
        
        user = "noreply@comcast.com"
        msg ['from'] = user
        
        server = smtplib.SMTP('mailrelay.comcast.com', 25)
        server.ehlo()
        server.starttls()
        server.ehlo()
        server.send_message(msg)
        server.quit()
        
        print(f"Error occurred in {func_name}: {error_message}")
        print(f"\nError Email Sent for {func_name} Updated")
    

#%% Line Break
def Line_Break():
    
    def date_function():
        timestr = time.strftime("%m%d%y")
        return timestr
    
    date = str(date_function())
    date = date[:2] + '/' + date[2:4] + '/' + date[4:6]
    
    print("\n", date, "\n")
    
#%% Automation

schedule.every().day.at("09:00").do(Line_Break)

#Every Day Scripts in order of time

schedule.every().day.at("09:30").do(Func_Data, ONTRAC_Combined_Orders, email_list_2, email_list_team_lauri)

schedule.every().day.at("10:00").do(Func_Data_Node_Analytics, Power_Supply_Outage_Detection, email_list_team_lauri, Func_Data_Power_Supply_string, email_list_team_lauri)

schedule.every().day.at("11:00").do(ML_Bonding, email_list_ml_bonding, email_list_team_lauri)

schedule.every().day.at("12:00").do(Func_SQL_Server_Jobs, server_287, email_subject_287, SQL_Server_Jobs, email_list_3, email_list_team_lauri)

schedule.every().day.at("12:00").do(Func_SQL_Server_Jobs, server_1145, email_subject_1145, SQL_Server_Jobs, email_list_3, email_list_team_lauri)

schedule.every().day.at("12:00").do(Func_SQL_Server_Jobs_24_Hours, server_287, SQL_Server_Jobs_24_Hours, email_subject_287, email_list_sql_server_24hours, email_list_team_lauri)

schedule.every().day.at("12:00").do(Func_SQL_Server_Jobs_24_Hours, server_1145, SQL_Server_Jobs_24_Hours, email_subject_1145, email_list_sql_server_24hours, email_list_team_lauri)

schedule.every().day.at("12:05").do(dx_dl_comcast_techops, email_list_comcast_techops, email_list_team_lauri)

schedule.every().day.at("14:00").do(Func_Data_Node_Analytics, Node_Analytics_Outage_Detection, email_list_7, Func_Data_Node_Analytics_string, email_list_team_lauri)

schedule.every().day.at("15:00").do(Func_Updated_287, PSNB_vs_Spatial_Trending, Table_Name[3], Table_Name_2[3], email_list_psnb_v_spatial, email_list_team_lauri)

schedule.every().day.at("15:00").do(Func_Updated_287, PS_Missing_EGIS_Daily, Table_Name[4], Table_Name_2[4], email_list_psnb_v_spatial, email_list_team_lauri)

schedule.every().day.at("15:00").do(Func_Updated, TechMPJProductivity, Table_Name[2], Table_Name_2[2], email_list_6, email_list_team_lauri)

#Tuesdays

#schedule.every().tuesday.at("12:00").do(Func_Updated, Calls_WeeklyReporting, Table_Name[0], Table_Name_2[0], email_list_1, email_list_team_lauri)

#schedule.every().tuesday.at("12:00").do(Func_Updated, TCs_WeeklyReporting, Table_Name[1], Table_Name_2[1], email_list_1, email_list_team_lauri)

#Thursday

schedule.every().thursday.at("10:00").do(Plant_Stability, california_query, region_cal, region_cal, email_list_california, email_list_team_lauri)

schedule.every().thursday.at("10:00").do(Plant_Stability, pnw_query, region_pnw, region_pnw_space, email_list_pnw, email_list_team_lauri)

while True:
    schedule.run_pending()
    time.sleep(600)


#%% Daily Packages
#Times in EST

# 9:30 AM EST
Func_Data(ONTRAC_Combined_Orders, email_list_2, email_list_team_lauri)

#10:00 am
Func_Data_Node_Analytics(Power_Supply_Outage_Detection, email_list_team_lauri, Func_Data_Power_Supply_string, email_list_team_lauri)

#11:00 am

ML_Bonding(email_list_ml_bonding, email_list_team_lauri)

#12:00 pm 
Func_SQL_Server_Jobs(server_287, email_subject_287, SQL_Server_Jobs, email_list_3, email_list_team_lauri)

Func_SQL_Server_Jobs(server_1145, email_subject_1145, SQL_Server_Jobs, email_list_3, email_list_team_lauri)

Func_SQL_Server_Jobs_24_Hours(server_287, SQL_Server_Jobs_24_Hours, email_list_sql_server_24hours, email_list_team_lauri)

Func_SQL_Server_Jobs_24_Hours(server_1145, SQL_Server_Jobs_24_Hours, email_list_sql_server_24hours, email_list_team_lauri)

#%%

Func_SQL_Server_Jobs_24_Hours(server_287, SQL_Server_Jobs_24_Hours, email_subject_287, email_list_test, email_list_test)

                              #%%
#12:05 pm 
dx_dl_comcast_techops(email_list_comcast_techops, email_list_team_lauri)

#%%
#2:00 pm
Func_Data_Node_Analytics(Node_Analytics_Outage_Detection, email_list_test, Func_Data_Node_Analytics_string, email_list_test)


#%%
Node_Analytics_Outage_Detection(email_list_7, Func_Data_Node_Analytics_string, email_list_team_lauri)

#%%
#3:00 pm 
Func_Updated_287(PSNB_vs_Spatial_Trending, Table_Name[3], Table_Name_2[3], email_list_psnb_v_spatial, email_list_team_lauri)

Func_Updated_287(PS_Missing_EGIS_Daily, Table_Name[4], Table_Name_2[4], email_list_psnb_v_spatial, email_list_team_lauri)

Func_Updated(TechMPJProductivity, Table_Name[2], Table_Name_2[2], email_list_6, email_list_team_lauri)

#Thursday

Plant_Stability(california_query, region_cal, region_cal, email_list_california, email_list_team_lauri)

Plant_Stability(pnw_query, region_pnw, region_pnw_space, email_list_pnw, email_list_team_lauri)

#%%Testing

Func_Data(ONTRAC_Combined_Orders, email_list_test, email_list_test)

Func_Data_Node_Analytics(Power_Supply_Outage_Detection, email_list_test, Func_Data_Power_Supply_string, email_list_test)

Func_Data_Node_Analytics(Node_Analytics_Outage_Detection, email_list_test, Func_Data_Node_Analytics_string, email_list_test)

Func_SQL_Server_Jobs(server_287, email_subject_287, SQL_Server_Jobs, email_list_test, email_list_test)

Func_SQL_Server_Jobs(server_1145, email_subject_1145, SQL_Server_Jobs, email_list_test, email_list_test)

Func_SQL_Server_Jobs_24_Hours(server_287, SQL_Server_Jobs_24_Hours, email_list_test, email_list_test)

Func_SQL_Server_Jobs_24_Hours(server_1145, SQL_Server_Jobs_24_Hours, email_list_test, email_list_test)

Spectra_Updated(Turners_Poll_Query, Turners_Poll_Last_7_Days, email_list_test, email_list_test)

Func_Updated_287(PSNB_vs_Spatial_Trending, Table_Name[3], Table_Name_2[3], email_list_test, email_list_test)

Func_Updated_287(PS_Missing_EGIS_Daily, Table_Name[4], Table_Name_2[4], email_list_test, email_list_test)

Func_Updated(TechMPJProductivity, Table_Name[2], Table_Name_2[2], email_list_test, email_list_test)

ML_Bonding(email_two_email_test, email_list_test)

dx_dl_comcast_techops(email_two_email_test, email_list_test)
